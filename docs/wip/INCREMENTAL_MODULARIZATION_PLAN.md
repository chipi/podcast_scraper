# Incremental Modularization Plan

**Status**: Draft  
**Related Documents**:

- `docs/wip/MODULARIZATION_REFACTORING_PLAN.md` - Overall refactoring strategy
- `docs/prd/PRD-006-openai-provider-integration.md` - OpenAI provider requirements
- `docs/rfc/RFC-013-openai-provider-implementation.md` - OpenAI implementation design
- `docs/rfc/RFC-016-modularization-for-ai-experiments.md` - Code structure refactoring

## Overview

This document provides a **risk-balanced, incremental implementation plan** for modularizing the podcast scraper architecture to support OpenAI provider integration and the AI experiment pipeline. Each stage is **complete, tested, and fully working** before moving to the next.

**Core Principles**:

1. âœ… Each stage delivers working functionality
2. âœ… Each stage is fully tested before proceeding
3. âœ… Backward compatibility maintained at every step
4. âœ… Incremental risk reduction (start with lowest risk)
5. âœ… Build on previous stages (no rework)

---

## Stage 0: Foundation & Preparation

**Goal**: Set up infrastructure with zero risk to existing functionality

**Duration**: 1-2 days  
**Risk Level**: âšª Very Low (no code changes, only additions)

### Deliverables

1. **Create package structure** (empty packages, no imports yet):

   ```text
   podcast_scraper/
   â”œâ”€â”€ preprocessing.py         # NEW (empty for now)
   â”œâ”€â”€ speaker_detectors/
   â”‚   â”œâ”€â”€ __init__.py
   â”‚   â”œâ”€â”€ base.py              # NEW (Protocol definitions only)
   â”‚   â””â”€â”€ factory.py           # NEW (empty factory)
   â”œâ”€â”€ transcription/
   â”‚   â”œâ”€â”€ __init__.py
   â”‚   â”œâ”€â”€ base.py              # NEW (Protocol definitions only)
   â”‚   â””â”€â”€ factory.py           # NEW (empty factory)
   â””â”€â”€ summarization/
       â”œâ”€â”€ __init__.py
       â”œâ”€â”€ base.py              # NEW (Protocol definitions only)
       â””â”€â”€ factory.py           # NEW (empty factory)
   ```

2. **Add config fields** (backward compatible defaults):
   ```python
   # config.py - Add new fields with defaults matching current behavior
   speaker_detector_type: Literal["ner", "openai"] = Field(default="ner")
   transcription_provider: Literal["whisper", "openai"] = Field(default="whisper")
   summary_provider: Literal["local", "openai"] = Field(default="local")
   openai_api_key: Optional[str] = Field(default=None)
   ```

3. **Create Protocol definitions** (no implementations yet):
   - `SpeakerDetector` protocol in `speaker_detectors/base.py`
   - `TranscriptionProvider` protocol in `transcription/base.py`
   - `SummarizationProvider` protocol in `summarization/base.py`

### Tests

- âœ… All existing tests pass (no regressions)
- âœ… Config validation tests for new fields
- âœ… Protocol type checking tests (verify protocols are valid)
- âœ… Import tests (verify new packages can be imported)

### Risk Mitigation

- **Risk**: New packages might cause import issues
  - **Mitigation**: Empty `__init__.py` files, no imports in workflow yet
- **Risk**: Config changes might break existing configs
  - **Mitigation**: All new fields have defaults matching current behavior

### Success Criteria

- âœ… New packages exist and can be imported
- âœ… Protocols are defined and type-checkable
- âœ… Config accepts new fields with defaults
- âœ… All existing tests pass
- âœ… No changes to existing functionality

---

## Stage 1: Extract Preprocessing Module

**Goal**: Extract provider-agnostic preprocessing to shared module

**Duration**: 1-2 days  
**Risk Level**: ðŸŸ¢ Low (isolated refactoring, easy to test)

### Stage 1 Deliverables

1. **Create `preprocessing.py` module**:
   - Move `clean_transcript()` from `summarizer.py`
   - Move `remove_sponsor_blocks()` from `summarizer.py`
   - Move `clean_for_summarization()` from `summarizer.py`
   - Keep function signatures identical (backward compatible)

2. **Update imports**:
   - Update `metadata.py` to import from `preprocessing.py`
   - Update `summarizer.py` to import from `preprocessing.py` (for backward compatibility)
   - Keep `summarizer.py` functions as wrappers initially (deprecation path)

3. **Add deprecation warnings** (optional, for future cleanup):
   - Add deprecation warnings in `summarizer.py` wrapper functions

### Stage 1 Tests

- âœ… Unit tests for each preprocessing function (moved from summarizer tests)
- âœ… Integration tests: `metadata.py` produces identical results
- âœ… Backward compatibility tests: `summarizer.py` functions still work
- âœ… Test with various transcript formats (timestamps, speakers, sponsors)

### Stage 1 Risk Mitigation

- **Risk**: Function behavior might change during move
  - **Mitigation**: Copy-paste exact code, add tests before refactoring
- **Risk**: Import paths might break
  - **Mitigation**: Keep wrapper functions in `summarizer.py` initially

### Stage 1 Success Criteria

- âœ… Preprocessing functions work identically in new location
- âœ… All existing tests pass
- âœ… `metadata.py` uses new preprocessing module
- âœ… No changes to output or behavior

---

## Stage 2: Transcription Provider Abstraction

**Goal**: Refactor transcription to use provider pattern (lowest coupling, easiest first)

**Duration**: 2-3 days  
**Risk Level**: ðŸŸ¡ Medium (refactoring core functionality)

### Stage 2 Deliverables

1. **Create `WhisperTranscriptionProvider`**:
   - Move `whisper_integration.py` logic to `transcription/whisper_provider.py`
   - Implement `TranscriptionProvider` protocol
   - Wrap existing functions as methods:
     - `initialize()` - Load Whisper model
     - `transcribe()` - Call `transcribe_with_whisper()`
     - `cleanup()` - Unload model

2. **Create factory**:
   - `TranscriptionProviderFactory.create()` returns `WhisperTranscriptionProvider` for `"whisper"`
   - Factory reads `transcription_provider` config field

3. **Update `workflow.py`**:
   - Replace direct `whisper_integration` imports with factory
   - Use provider pattern for transcription
   - Keep `_TranscriptionResources` but update to use provider

4. **Update `episode_processor.py`** (if exists):
   - Use provider instead of direct Whisper calls

### Stage 2 Tests

- âœ… Unit tests for `WhisperTranscriptionProvider` (mock Whisper)
- âœ… Protocol compliance tests (verify implements `TranscriptionProvider`)
- âœ… Integration tests: Transcription produces identical results
- âœ… Factory tests: Factory returns correct provider
- âœ… End-to-end tests: Full workflow with transcription works

### Stage 2 Risk Mitigation

- **Risk**: Transcription might break during refactoring
  - **Mitigation**: Copy-paste exact logic, test thoroughly before switching
- **Risk**: Resource management might leak
  - **Mitigation**: Test cleanup() is called, verify no memory leaks

### Stage 2 Success Criteria

- âœ… Transcription works identically via provider
- âœ… All existing transcription tests pass
- âœ… Factory pattern works correctly
- âœ… No memory leaks or resource issues
- âœ… Backward compatible (default behavior unchanged)

---

## Stage 3: Speaker Detection Provider Abstraction

**Goal**: Refactor speaker detection to use provider pattern

**Duration**: 2-3 days  
**Risk Level**: ðŸŸ¡ Medium (moderate coupling, well-isolated)

### Stage 3 Deliverables

1. **Refactor `speaker_detection.py` â†’ `speaker_detectors/ner_detector.py`**:
   - Extract helper functions from large functions:
     - `_calculate_heuristic_score()` from `detect_speaker_names()`
     - `_build_guest_candidates()` from `detect_speaker_names()`
     - `_select_best_guest()` from `detect_speaker_names()`
     - `_extract_entities_from_text()` from `extract_person_entities()`
     - `_extract_entities_from_segments()` from `extract_person_entities()`
     - `_pattern_based_fallback()` from `extract_person_entities()`
   - Implement `SpeakerDetector` protocol
   - Wrap existing functions as methods:
     - `detect_hosts()` - Call `detect_hosts_from_feed()`
     - `detect_speakers()` - Call `detect_speaker_names()`
     - `analyze_patterns()` - Call pattern analysis functions

2. **Create factory**:
   - `SpeakerDetectorFactory.create()` returns `NERSpeakerDetector` for `"ner"`
   - Factory reads `speaker_detector_type` config field

3. **Update `workflow.py`**:
   - Replace direct `speaker_detection` imports with factory
   - Use provider pattern for speaker detection

### Stage 3 Tests

- âœ… Unit tests for `NERSpeakerDetector` (mock spaCy)
- âœ… Protocol compliance tests (verify implements `SpeakerDetector`)
- âœ… Integration tests: Speaker detection produces identical results
- âœ… Factory tests: Factory returns correct provider
- âœ… End-to-end tests: Full workflow with speaker detection works
- âœ… Test extracted helper functions independently

### Stage 3 Risk Mitigation

- **Risk**: Speaker detection logic might break during extraction
  - **Mitigation**: Extract functions incrementally, test after each extraction
- **Risk**: Large functions might be hard to refactor
  - **Mitigation**: Extract helper functions first, then wrap in protocol

### Stage 3 Success Criteria

- âœ… Speaker detection works identically via provider
- âœ… All existing speaker detection tests pass
- âœ… Helper functions are testable independently
- âœ… Factory pattern works correctly
- âœ… Code is more maintainable (smaller functions)

---

## Stage 4: Summarization Provider Abstraction

**Goal**: Refactor summarization to use provider pattern (most complex, done last)

**Duration**: 3-4 days  
**Risk Level**: ðŸŸ  Medium-High (most coupling, complex logic)

### Stage 4 Deliverables

1. **Refactor `summarizer.py` â†’ `summarization/local_provider.py`**:
   - Move `SummaryModel` class to `LocalSummarizationProvider`
   - Implement `SummarizationProvider` protocol
   - Wrap existing methods:
     - `initialize()` - Load model (current `__init__` logic)
     - `summarize()` - Call `generate_summary()` for single text
     - `summarize_chunks()` - Call `generate_summary()` for chunks (MAP phase)
     - `combine_summaries()` - Call `generate_summary()` for final combine (REDUCE phase)
     - `cleanup()` - Unload model (current cleanup logic)

2. **Create factory**:
   - `SummarizationProviderFactory.create()` returns `LocalSummarizationProvider` for `"local"`
   - Factory reads `summary_provider` config field

3. **Update `workflow.py`**:
   - Replace direct `summarizer` imports with factory
   - Use provider pattern for summarization
   - Pass provider to `metadata.py` functions

4. **Update `metadata.py`**:
   - Refactor `_generate_episode_summary()` to use provider
   - Use provider's `summarize_chunks()` and `combine_summaries()` methods
   - Remove direct `summarizer` imports (use provider instead)

### Stage 4 Tests

- âœ… Unit tests for `LocalSummarizationProvider` (mock transformers)
- âœ… Protocol compliance tests (verify implements `SummarizationProvider`)
- âœ… Integration tests: Summarization produces identical results
- âœ… Factory tests: Factory returns correct provider
- âœ… End-to-end tests: Full workflow with summarization works
- âœ… Test MAP/REDUCE phases independently
- âœ… Test model loading/unloading (memory management)

### Stage 4 Risk Mitigation

- **Risk**: Model loading/unloading might break
  - **Mitigation**: Test memory management thoroughly, verify cleanup
- **Risk**: MAP/REDUCE logic might break during refactoring
  - **Mitigation**: Test each phase independently, verify end-to-end
- **Risk**: `metadata.py` refactoring might be complex
  - **Mitigation**: Refactor incrementally, test after each change

### Stage 4 Success Criteria

- âœ… Summarization works identically via provider
- âœ… All existing summarization tests pass
- âœ… MAP/REDUCE phases work correctly
- âœ… Factory pattern works correctly
- âœ… Memory management works (no leaks)
- âœ… `metadata.py` is cleaner (uses provider)

---

## Stage 5: Provider Integration & Testing

**Goal**: Ensure all providers work together, comprehensive testing

**Duration**: 2-3 days  
**Risk Level**: ðŸŸ¡ Medium (integration testing)

### Stage 5 Deliverables

1. **Integration tests**:
   - Test workflow with all providers (transcription, speaker detection, summarization)
   - Test provider switching (change config, verify behavior)
   - Test error handling (provider fails, verify graceful handling)

2. **Protocol compliance tests**:
   - Verify all providers implement protocols correctly
   - Test type checking (mypy compliance)

3. **Backward compatibility tests**:
   - Test default behavior (all local providers)
   - Test existing configs still work
   - Test existing CLI commands still work

4. **Performance tests**:
   - Compare performance (provider vs direct calls)
   - Verify no performance regression

5. **Documentation**:
   - Update docstrings for providers
   - Document provider interfaces
   - Add examples for each provider

### Stage 5 Tests

- âœ… Full pipeline integration tests
- âœ… Provider switching tests
- âœ… Error handling tests
- âœ… Backward compatibility tests
- âœ… Performance benchmarks
- âœ… Protocol compliance tests

### Stage 5 Risk Mitigation

- **Risk**: Integration issues might surface
  - **Mitigation**: Comprehensive integration tests, fix issues before proceeding
- **Risk**: Performance might degrade
  - **Mitigation**: Benchmark before/after, optimize if needed

### Stage 5 Success Criteria

- âœ… All providers work together correctly
- âœ… All integration tests pass
- âœ… No performance regression
- âœ… Backward compatibility maintained
- âœ… Documentation complete

---

## Stage 6: OpenAI Provider Implementation (Optional - After Core Refactoring)

**Goal**: Add OpenAI providers for each capability

**Duration**: 3-5 days per provider (can be done incrementally)  
**Risk Level**: ðŸŸ¡ Medium (new functionality, well-isolated)

### Prerequisites

- âœ… Stages 0-5 completed
- âœ… Provider pattern fully implemented
- âœ… All tests passing

### Implementation Order

1. **OpenAI Transcription Provider** (easiest, most isolated)
2. **OpenAI Speaker Detection Provider** (moderate complexity)
3. **OpenAI Summarization Provider** (most complex, leverages large context window)

### Deliverables (Per Provider)

1. **Create provider implementation**:
   - `transcription/openai_provider.py`
   - `speaker_detectors/openai_detector.py`
   - `summarization/openai_provider.py`

2. **Update factories**:
   - Add OpenAI provider to factory selection logic

3. **Add config validation**:
   - Validate API key when OpenAI provider selected
   - Add per-provider model configuration

4. **Tests**:
   - Unit tests with mocked OpenAI API
   - Integration tests with real API (optional, requires key)
   - Error handling tests (API failures, rate limits)

### Success Criteria (Per Provider)

- âœ… Provider implements protocol correctly
- âœ… All protocol tests pass
- âœ… Integration tests pass (with mocked API)
- âœ… Error handling works correctly
- âœ… Documentation complete

---

## Risk Assessment Summary

| Stage | Risk Level | Mitigation Strategy |
| ----- | ---------- | -------------------- |
| Stage 0: Foundation | âšª Very Low | Empty packages, defaults match current behavior |
| Stage 1: Preprocessing | ðŸŸ¢ Low | Isolated refactoring, easy to test |
| Stage 2: Transcription | ðŸŸ¡ Medium | Well-isolated, copy-paste logic |
| Stage 3: Speaker Detection | ðŸŸ¡ Medium | Extract incrementally, test frequently |
| Stage 4: Summarization | ðŸŸ  Medium-High | Most complex, done last with experience |
| Stage 5: Integration | ðŸŸ¡ Medium | Comprehensive testing |
| Stage 6: OpenAI | ðŸŸ¡ Medium | Well-isolated, optional, can be incremental |

---

## Testing Strategy

### Unit Tests (Each Stage)

- Test individual functions/methods
- Mock external dependencies (spaCy, Whisper, transformers, OpenAI)
- Test error handling
- Test edge cases

### Integration Tests (Each Stage)

- Test provider with real dependencies (where feasible)
- Test workflow integration
- Test config handling
- Test resource management

### Protocol Compliance Tests (Stages 2-4)

- Verify providers implement protocols correctly
- Test type checking (mypy)
- Test interface contracts

### Backward Compatibility Tests (All Stages)

- Test default behavior unchanged
- Test existing configs still work
- Test existing CLI commands still work
- Test existing output format unchanged

### Performance Tests (Stage 5)

- Benchmark before/after refactoring
- Verify no performance regression
- Test memory usage

---

## Success Metrics

### Code Quality

- âœ… All existing tests pass (no regressions)
- âœ… New tests added for each stage
- âœ… Code coverage maintained or improved
- âœ… Type checking passes (mypy)
- âœ… Linting passes (flake8, black)

### Functionality

- âœ… All existing functionality works identically
- âœ… Provider pattern works correctly
- âœ… Factory pattern works correctly
- âœ… Backward compatibility maintained

### Maintainability

- âœ… Code is more modular (smaller functions)
- âœ… Clear separation of concerns
- âœ… Protocols are well-defined
- âœ… Documentation is complete

---

## Timeline Estimate

| Stage | Duration | Cumulative |
| ----- | -------- | ---------- |
| Stage 0: Foundation | 1-2 days | 1-2 days |
| Stage 1: Preprocessing | 1-2 days | 2-4 days |
| Stage 2: Transcription | 2-3 days | 4-7 days |
| Stage 3: Speaker Detection | 2-3 days | 6-10 days |
| Stage 4: Summarization | 3-4 days | 9-14 days |
| Stage 5: Integration | 2-3 days | 11-17 days |
| Stage 6: OpenAI (optional) | 3-5 days each | 14-32 days |

**Total Core Refactoring**: ~11-17 days (2-3 weeks)  
**With OpenAI Providers**: ~14-32 days (3-6 weeks)

---

## Dependencies Between Stages

```text
Stage 0 (Foundation)
  â†“
Stage 1 (Preprocessing) - Independent
  â†“
Stage 2 (Transcription) - Independent
  â†“
Stage 3 (Speaker Detection) - Independent
  â†“
Stage 4 (Summarization) - Uses preprocessing from Stage 1
  â†“
Stage 5 (Integration) - Requires all Stages 1-4
  â†“
Stage 6 (OpenAI) - Requires Stage 5
```

**Note**: Stages 1-4 can be done in parallel after Stage 0, but sequential is recommended for risk management.

---

## Rollback Plan

If any stage fails or introduces issues:

1. **Immediate**: Revert to previous stage (git revert)
2. **Investigation**: Identify root cause
3. **Fix**: Address issue in isolation
4. **Re-test**: Verify fix works
5. **Continue**: Proceed to next stage

Each stage is designed to be independently revertible without affecting previous stages.

---

## Next Steps

1. **Review this plan** with stakeholders
2. **Set up development branch**: `feature/modularization-refactoring`
3. **Start with Stage 0**: Foundation & Preparation
4. **Iterate**: Complete each stage fully before proceeding
5. **Document**: Update this plan with lessons learned

---

## Notes

- This plan prioritizes **risk reduction** and **incremental value delivery**
- Each stage can be **reviewed and approved** independently
- **OpenAI providers** can be added later (Stage 6) or in parallel by different developers
- **Testing is critical** at each stage - don't proceed without passing tests
- **Backward compatibility** is maintained at every step
