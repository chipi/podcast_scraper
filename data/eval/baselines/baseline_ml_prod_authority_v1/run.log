2026-02-01 21:15:16,810 INFO __main__: ================================================================================
2026-02-01 21:15:16,810 INFO __main__: Starting experiment run: baseline_ml_prod_candidate_v1_benchmark
2026-02-01 21:15:16,810 INFO __main__: Results directory: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark
2026-02-01 21:15:16,810 INFO __main__: Execution log: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/run.log
2026-02-01 21:15:16,810 INFO __main__: Dataset: curated_5feeds_benchmark_v1
2026-02-01 21:15:16,810 INFO __main__: ================================================================================
2026-02-01 21:15:16,810 INFO __main__: Creating summarization provider...
2026-02-01 21:15:16,810 INFO __main__: Checking if required models are cached...
2026-02-01 21:15:17,631 INFO podcast_scraper.providers.ml.ml_provider: Initializing Transformers summarization models...
2026-02-01 21:15:17,631 INFO podcast_scraper.providers.ml.ml_provider: Loading MAP model: google/pegasus-cnn_dailymail
2026-02-01 21:15:18,461 INFO podcast_scraper.providers.ml.summarizer: Loading summarization model: google/pegasus-cnn_dailymail on mps (Apple Silicon GPU)
2026-02-01 21:15:20,456 INFO podcast_scraper.providers.ml.ml_provider: ✓ MAP model loaded: google/pegasus-cnn_dailymail
2026-02-01 21:15:20,456 INFO podcast_scraper.providers.ml.ml_provider: Loading REDUCE model: allenai/led-base-16384
2026-02-01 21:15:20,456 INFO podcast_scraper.providers.ml.summarizer: Loading summarization model: allenai/led-base-16384 on mps (Apple Silicon GPU)
2026-02-01 21:15:20,744 INFO podcast_scraper.providers.ml.ml_provider: ✓ REDUCE model loaded: allenai/led-base-16384
2026-02-01 21:15:20,744 INFO podcast_scraper.providers.ml.ml_provider: Transformers summarization initialized successfully
2026-02-01 21:15:20,744 INFO __main__: ================================================================================
2026-02-01 21:15:20,744 INFO __main__: === Generation Parameters ===
2026-02-01 21:15:20,744 INFO __main__: Map stage:
2026-02-01 21:15:20,744 INFO __main__:   Model: google/pegasus-cnn_dailymail
2026-02-01 21:15:20,744 INFO __main__:   max_new_tokens: 200
2026-02-01 21:15:20,744 INFO __main__:   min_new_tokens: 80
2026-02-01 21:15:20,744 INFO __main__:   num_beams: 6
2026-02-01 21:15:20,744 INFO __main__:   no_repeat_ngram_size: 3
2026-02-01 21:15:20,744 INFO __main__:   length_penalty: 1.0
2026-02-01 21:15:20,744 INFO __main__:   early_stopping: True
2026-02-01 21:15:20,745 INFO __main__:   repetition_penalty: 1.1
2026-02-01 21:15:20,745 INFO __main__: Reduce stage:
2026-02-01 21:15:20,745 INFO __main__:   Model: allenai/led-base-16384
2026-02-01 21:15:20,745 INFO __main__:   max_new_tokens: 650
2026-02-01 21:15:20,745 INFO __main__:   min_new_tokens: 220
2026-02-01 21:15:20,745 INFO __main__:   num_beams: 4
2026-02-01 21:15:20,745 INFO __main__:   no_repeat_ngram_size: 3
2026-02-01 21:15:20,745 INFO __main__:   length_penalty: 1.0
2026-02-01 21:15:20,745 INFO __main__:   early_stopping: False
2026-02-01 21:15:20,745 INFO __main__:   repetition_penalty: 1.12
2026-02-01 21:15:20,745 INFO __main__: Tokenization:
2026-02-01 21:15:20,745 INFO __main__:   map_max_input_tokens: 1024
2026-02-01 21:15:20,745 INFO __main__:   reduce_max_input_tokens: 4096
2026-02-01 21:15:20,745 INFO __main__:   truncation: True
2026-02-01 21:15:20,745 INFO __main__: Chunking:
2026-02-01 21:15:20,745 INFO __main__:   strategy: word_chunking
2026-02-01 21:15:20,745 INFO __main__:   word_chunk_size: 900
2026-02-01 21:15:20,745 INFO __main__:   word_overlap: 150
2026-02-01 21:15:20,745 INFO __main__: Preprocessing:
2026-02-01 21:15:20,745 INFO __main__:   profile: cleaning_v4
2026-02-01 21:15:20,745 INFO __main__: ================================================================================
2026-02-01 21:15:20,844 INFO __main__: Found 10 episode(s) to process
2026-02-01 21:15:20,844 INFO __main__: Phase 1: Running inference...
2026-02-01 21:15:20,845 INFO __main__: Processing episode: p01_e01
2026-02-01 21:15:20,845 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:15:20,846 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:15:20,847 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:15:20,847 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:15:20,847 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:15:20,847 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:15:20,847 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:15:20,855 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 56 → 50 (6 removed), chars: 11,049 → 10,793 (256 removed, 2.3%)
2026-02-01 21:15:20,855 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:15:50,339 INFO __main__: Episode p01_e01 map/reduce stats: map_chunks=5, avg_map_summary=432 chars, reduce_input=1,115 chars
2026-02-01 21:15:50,339 INFO __main__: Episode p01_e01 completed in 29.5s, summary length=909 chars
2026-02-01 21:15:50,339 INFO __main__: Processing episode: p01_e02
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:15:50,340 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:15:50,345 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 57 → 51 (6 removed), chars: 11,059 → 10,749 (310 removed, 2.8%)
2026-02-01 21:15:50,345 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:16:13,417 WARNING podcast_scraper.providers.ml.summarizer: Final summary (830 chars) is LONGER than input (803 chars). Model expanded instead of summarizing. This may indicate model issues or input already being very concise.
2026-02-01 21:16:13,418 INFO __main__: Episode p01_e02 map/reduce stats: map_chunks=5, avg_map_summary=424 chars, reduce_input=803 chars
2026-02-01 21:16:13,418 INFO __main__: Episode p01_e02 completed in 23.1s, summary length=830 chars
2026-02-01 21:16:13,418 INFO __main__: Processing episode: p02_e01
2026-02-01 21:16:13,418 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:16:13,419 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:16:13,424 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 58 → 52 (6 removed), chars: 11,537 → 11,225 (312 removed, 2.7%)
2026-02-01 21:16:13,424 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:16:36,901 WARNING podcast_scraper.providers.ml.summarizer: Final summary (864 chars) is LONGER than input (803 chars). Model expanded instead of summarizing. This may indicate model issues or input already being very concise.
2026-02-01 21:16:36,902 INFO __main__: Episode p02_e01 map/reduce stats: map_chunks=5, avg_map_summary=422 chars, reduce_input=803 chars
2026-02-01 21:16:36,902 INFO __main__: Episode p02_e01 completed in 23.5s, summary length=864 chars
2026-02-01 21:16:36,903 INFO __main__: Processing episode: p02_e02
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:16:36,903 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:16:36,908 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 59 → 53 (6 removed), chars: 11,265 → 10,942 (323 removed, 2.9%)
2026-02-01 21:16:36,908 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:17:00,915 WARNING podcast_scraper.providers.ml.summarizer: Final summary (910 chars) is LONGER than input (894 chars). Model expanded instead of summarizing. This may indicate model issues or input already being very concise.
2026-02-01 21:17:00,916 INFO __main__: Episode p02_e02 map/reduce stats: map_chunks=5, avg_map_summary=416 chars, reduce_input=894 chars
2026-02-01 21:17:00,916 INFO __main__: Episode p02_e02 completed in 24.0s, summary length=910 chars
2026-02-01 21:17:00,916 INFO __main__: Processing episode: p03_e01
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:17:00,916 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:17:00,917 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:17:00,922 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 58 → 52 (6 removed), chars: 10,679 → 10,395 (284 removed, 2.7%)
2026-02-01 21:17:00,922 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:17:21,036 WARNING podcast_scraper.providers.ml.summarizer: Final summary (966 chars) is LONGER than input (797 chars). Model expanded instead of summarizing. This may indicate model issues or input already being very concise.
2026-02-01 21:17:21,037 INFO __main__: Episode p03_e01 map/reduce stats: map_chunks=4, avg_map_summary=432 chars, reduce_input=797 chars
2026-02-01 21:17:21,037 INFO __main__: Episode p03_e01 completed in 20.1s, summary length=966 chars
2026-02-01 21:17:21,037 INFO __main__: Processing episode: p03_e02
2026-02-01 21:17:21,037 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:17:21,037 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:17:21,037 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:17:21,038 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:17:21,043 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 62 → 56 (6 removed), chars: 11,172 → 10,874 (298 removed, 2.7%)
2026-02-01 21:17:21,043 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:17:44,750 INFO __main__: Episode p03_e02 map/reduce stats: map_chunks=5, avg_map_summary=408 chars, reduce_input=1,278 chars
2026-02-01 21:17:44,750 INFO __main__: Episode p03_e02 completed in 23.7s, summary length=879 chars
2026-02-01 21:17:44,751 INFO __main__: Processing episode: p04_e01
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:17:44,751 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:17:44,756 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 57 → 51 (6 removed), chars: 10,723 → 10,518 (205 removed, 1.9%)
2026-02-01 21:17:44,756 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:18:03,672 WARNING podcast_scraper.providers.ml.summarizer: Final summary (950 chars) is LONGER than input (673 chars). Model expanded instead of summarizing. This may indicate model issues or input already being very concise.
2026-02-01 21:18:03,673 INFO __main__: Episode p04_e01 map/reduce stats: map_chunks=4, avg_map_summary=422 chars, reduce_input=673 chars
2026-02-01 21:18:03,673 INFO __main__: Episode p04_e01 completed in 18.9s, summary length=950 chars
2026-02-01 21:18:03,673 INFO __main__: Processing episode: p04_e02
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:18:03,674 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:18:03,679 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 60 → 54 (6 removed), chars: 10,913 → 10,645 (268 removed, 2.5%)
2026-02-01 21:18:03,679 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:18:24,432 WARNING podcast_scraper.providers.ml.summarizer: Final summary (956 chars) is LONGER than input (927 chars). Model expanded instead of summarizing. This may indicate model issues or input already being very concise.
2026-02-01 21:18:24,433 INFO __main__: Episode p04_e02 map/reduce stats: map_chunks=5, avg_map_summary=391 chars, reduce_input=927 chars
2026-02-01 21:18:24,433 INFO __main__: Episode p04_e02 completed in 20.8s, summary length=956 chars
2026-02-01 21:18:24,434 INFO __main__: Processing episode: p05_e01
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:18:24,434 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:18:24,439 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 62 → 56 (6 removed), chars: 11,190 → 10,862 (328 removed, 2.9%)
2026-02-01 21:18:24,439 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:18:45,513 INFO __main__: Episode p05_e01 map/reduce stats: map_chunks=4, avg_map_summary=489 chars, reduce_input=1,023 chars
2026-02-01 21:18:45,513 INFO __main__: Episode p05_e01 completed in 21.1s, summary length=985 chars
2026-02-01 21:18:45,514 INFO __main__: Processing episode: p05_e02
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider: === Using ML Parameters from Config ===
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider: Map stage:
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 200
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 80
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 6
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: True
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.1
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider: Reduce stage:
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   max_new_tokens: 650
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   min_new_tokens: 220
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   num_beams: 4
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   no_repeat_ngram_size: 3
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   length_penalty: 1.0
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   early_stopping: False
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   repetition_penalty: 1.12
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider: Tokenization:
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   map_max_input_tokens: 1024
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   reduce_max_input_tokens: 4096
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   truncation: True
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider: Chunking:
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   strategy: word_chunking
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   word_chunk_size: 900
2026-02-01 21:18:45,514 INFO podcast_scraper.providers.ml.ml_provider:   word_overlap: 150
2026-02-01 21:18:45,519 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Profile: cleaning_v4, lines: 66 → 60 (6 removed), chars: 11,679 → 11,324 (355 removed, 3.0%)
2026-02-01 21:18:45,519 INFO podcast_scraper.providers.ml.summarizer: [PREPROCESSING] Steps: step_header_stripped: 5, step_standard_cleaning: 1
2026-02-01 21:19:10,492 INFO __main__: Episode p05_e02 map/reduce stats: map_chunks=5, avg_map_summary=446 chars, reduce_input=1,069 chars
2026-02-01 21:19:10,492 INFO __main__: Episode p05_e02 completed in 25.0s, summary length=918 chars
2026-02-01 21:19:10,493 INFO __main__: Phase 1 completed in 229.6s
2026-02-01 21:19:10,493 INFO __main__: Total input: 111,266 chars, output: 9,167 chars
2026-02-01 21:19:10,493 INFO __main__: Average compression: 12.1x
2026-02-01 21:19:10,493 INFO __main__: Predictions: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/predictions.jsonl
2026-02-01 21:19:10,493 INFO __main__: Metadata: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/baseline.json
2026-02-01 21:19:10,493 INFO __main__: Fingerprint: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/fingerprint.json
2026-02-01 21:19:10,493 INFO __main__: Created README.md: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/README.md
2026-02-01 21:19:10,497 INFO __main__: Computing metrics...
2026-02-01 21:19:10,498 INFO __main__: Metrics: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/metrics.json
2026-02-01 21:19:10,499 INFO podcast_scraper.evaluation.reporter: Report saved to: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/metrics_report.md
2026-02-01 21:19:10,499 INFO __main__: Episodes=10, avg_time=23.0s, avg_compression=12.1x
2026-02-01 21:19:10,708 INFO __main__: ✓ Execution log saved: data/eval/runs/baseline_ml_prod_candidate_v1_benchmark/run.log
