[build-system]
requires = ["setuptools>=65"]
build-backend = "setuptools.build_meta"

[project]
name = "podcast-scraper"
version = "2.5.0"
description = "Download podcast transcripts from RSS feeds with optional Whisper fallback"
readme = "README.md"
authors = [{name = "Podcast Scraper Maintainers"}]
license = "MIT"
requires-python = ">=3.10"
dependencies = [
  "requests>=2.31.0,<3.0.0",
  "urllib3>=2.6.0,<3.0.0",
  "tqdm>=4.66.0,<5.0.0",
  "defusedxml>=0.7.1,<1.0.0",
  "platformdirs>=3.11.0,<5.0.0",
  "pydantic>=2.6.0,<3.0.0",
  "PyYAML>=6.0,<7.0.0",
  "python-dotenv>=1.0.0,<2.0.0",  # For .env file support (RFC-013)
  "zipp>=3.19.1,<4.0.0",  # Security fix: CVE-2024-50208 (infinite loop vulnerability)
  "jinja2>=3.1.0,<4.0.0",  # For prompt templating (RFC-017)
  "openai>=1.0.0,<2.0.0",  # For OpenAI API providers (RFC-013)
  "filelock>=3.20.1,<4.0.0",  # Security fix: CVE-2025-68146 (TOCTOU race condition)
]

[project.optional-dependencies]
# Heavy ML dependencies - only install when needed
ml = [
  "openai-whisper>=20231117",
  "spacy>=3.7.0,<4.0.0",
  # spaCy language models are distributed via GitHub releases (not PyPI) due to size constraints.
  # This is the official and standard method recommended by spaCy.
  # Version compatibility: spaCy 3.7.x requires en_core_web_sm 3.7.x
  # See: https://spacy.io/usage/models for model version compatibility
  "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl",
  "torch>=2.0.0,<3.0.0",
  "transformers>=4.30.0,<5.0.0",
  "sentencepiece>=0.1.99,<1.0.0",
  "accelerate>=0.20.0,<1.0.0",
  "protobuf>=3.20.0,<7.0.0",
]
# Development tools
dev = [
  "black>=23.0.0,<25.0.0",
  "isort>=5.12.0,<8.0.0",
  "flake8>=6.0.0,<8.0.0",
  "pytest>=7.4.0,<10.0.0",
  "pytest-cov>=4.1.0,<8.0.0",
  "pytest-xdist>=3.5.0,<4.0.0",  # Parallel test execution (RFC-018)
  "pytest-rerunfailures>=14.0,<17.0",  # Flaky test reruns (RFC-018)
  "pytest-socket>=0.7.0,<1.0.0",  # Network blocking for E2E tests (RFC-019)
  "pytest-json-report>=1.5.0,<2.0.0",  # JSON test reports for metrics (RFC-025)
  "mypy>=1.5.0,<2.0.0",
  "types-PyYAML>=6.0.12,<7.0.0",
  "bandit>=1.7.5,<2.0.0",
  "pip-audit>=2.6.0,<3.0.0",
  "build",
  "rouge-score>=0.1.2,<1.0.0",  # Required for scripts/eval/eval_summaries.py
  "radon>=6.0.0,<7.0.0",  # Code complexity analysis (RFC-031)
  "vulture>=2.10,<3.0.0",  # Dead code detection (RFC-031)
  "interrogate>=1.5.0,<2.0.0",  # Docstring coverage (RFC-031)
  "codespell>=2.2.0,<3.0.0",  # Spell checking (RFC-031)
  "pydeps>=1.12.0,<2.0.0",  # Module dependency visualization (RFC-038, #170)
]
# Documentation - see docs/requirements.txt

[tool.setuptools]
# Package is now in src/ directory (src-layout)
packages = [
    "podcast_scraper",
    "podcast_scraper.speaker_detectors",
    "podcast_scraper.summarization",
    "podcast_scraper.transcription",
    "podcast_scraper.workflow",
    "podcast_scraper.workflow.stages",
]
package-dir = {"" = "src"}

[tool.black]
line-length = 100
target-version = ["py310"]
include = '\.(py|pyi)$'
exclude = '''
(
  /(
      \.git
    | \.mypy_cache
    | \.pytest_cache
    | \.venv
    | \.build
    | \.test_outputs
    | build
    | dist
    | __pycache__
  )/
)
'''

[tool.isort]
profile = "black"
line_length = 100
known_first_party = ["podcast_scraper"]
combine_as_imports = true
force_alphabetical_sort_within_sections = true

[tool.mypy]
python_version = "3.10"
ignore_missing_imports = true
warn_return_any = true
warn_unused_configs = true
exclude = [
    "^scripts/.*",  # Scripts use sys.path manipulation, exclude from mypy
]

[[tool.mypy.overrides]]
module = ["requests", "requests.*"]
ignore_missing_imports = true

[tool.coverage.run]
branch = true
source = ["podcast_scraper"]

[tool.coverage.report]
show_missing = true
skip_covered = true
precision = 2
# Note: fail_under is NOT set globally because different test types have different coverage:
# - Unit tests: ~70-80% (isolated, high coverage)
# - Integration tests: ~40-60% (component interactions, lower coverage)
# - E2E tests: ~30-50% (happy paths only)
# Per-test-type thresholds are enforced via --cov-fail-under in Makefile and CI:
# - Integration: 50% (COVERAGE_THRESHOLD_INTEGRATION)
# - E2E: 50% (COVERAGE_THRESHOLD_E2E)
# - Combined: 80% (COVERAGE_THRESHOLD_COMBINED) - enforced in coverage-unified job only
# See .github/workflows/python-app.yml for CI enforcement.

[tool.pytest.ini_options]
testpaths = ["tests"]
# Default: run only unit tests (fast feedback)
# Note: -m marker filter removed from addopts to avoid conflicts with explicit -m flags
# Use explicit -m flags in Makefile/CI commands instead
addopts = "-q -ra"
# Suppress warnings from external libraries that we can't fix
filterwarnings = [
    # spaCy/Click deprecation warning (external library, will be fixed in future Click version)
    "ignore::DeprecationWarning:spacy.cli._util",
    # Whisper FP16 warning (expected on CPU, harmless)
    "ignore::UserWarning:whisper.transcribe",
]
# Parallel execution: use -n auto to enable, or -n 0 to disable
# Reruns: use --reruns 2 --reruns-delay 1 for flaky tests
markers = [
    "analysis: diagnostic/analysis tools (not run in regular test suites)",
    "analytical: analytical/diagnostic test tools (separate from regular tests, in tests/analytical/)",
    "unit: marks tests as unit tests (deselect with '-m \"not unit\"')",
    "multi_episode: multi-episode tests with multiple short episodes (10-15 seconds each) for testing multi-episode processing logic",
    "data_quality: data quality validation tests with multiple episodes (nightly only)",
    "nightly: marks tests as nightly-only (comprehensive tests with production models, not run in regular CI)",
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: integration tests (slower, test component interactions)",
    "e2e: end-to-end workflow tests (slowest, test full workflows)",
    "network: hits the network (off by default, use -m network to enable)",
    "ml_models: requires ML dependencies and real model loading (requires openai-whisper, spacy, transformers)",
    "critical_path: marks tests as part of the critical path (RSS → Parse → Download/Transcribe → NER → Summarization → Metadata → Files). These tests run in fast suite regardless of ml_models marker if models are cached.",
    "llm: tests that use LLM APIs (may incur costs or rate limits, includes openai and future providers)",
    "openai: tests that use OpenAI API specifically (subset of llm marker)",
    "integration_http: HTTP integration tests (use real HTTP client with test server, not external network)",
    "infrastructure: tests for test infrastructure itself (pytest markers, Makefile, CI config)",
    "serial: marks tests that must run sequentially (not in parallel) due to resource conflicts or race conditions",
    "flaky: marks tests as potentially flaky (may fail intermittently in parallel execution, should use reruns)",
]
# Parallel execution configuration (pytest-xdist)
# Use -n auto to automatically detect CPU count, or -n N for specific number
# Use -n 0 to disable parallel execution
# Reruns configuration (pytest-rerunfailures)
# Use --reruns N to retry failed tests N times
# Use --reruns-delay N to wait N seconds between retries
# Network blocking configuration (pytest-socket) for E2E tests
# Block all external network calls except localhost/127.0.0.1
# This is configured per-test-directory in conftest.py files

[tool.interrogate]
ignore-init-module = true
ignore-init-method = true
ignore-magic = true
ignore-semiprivate = true
ignore-private = true
ignore-property-decorators = true
ignore-module = true
ignore-nested-functions = true
fail-under = 60
exclude = ["tests", "scripts"]
verbose = 1
