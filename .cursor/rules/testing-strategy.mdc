# Testing Strategy - Quick Reference

**For complete details:** `docs/guides/TESTING_GUIDE.md`, `docs/TESTING_STRATEGY.md`

## ðŸš¨ After Code Changes: Test Review Checklist

**CRITICAL: Never leave failing tests after code changes.**

After any code session with new/modified code, MUST review related tests:

1. **Review hierarchy** (bottom to top): unit â†’ integration â†’ e2e
2. **Adjust tests** to match new code behavior (update assertions, mocks, fixtures)
3. **Run tests** at each level and ensure ALL pass before considering work complete
4. **If tests fail, fix them immediately** â€” don't defer or skip

### Test Review Questions

- Unit tests: Do they cover the changed code paths?
- Integration tests: Do they reflect new behavior correctly?
- E2E tests: Do end-to-end flows still work?
- All tests pass: `make test-unit`, `make test-integration`, `make test-e2e`

If you're unsure which tests are affected, run the full test suite and fix failures.

## ðŸš¨ MANDATORY: Testing Before Commit

**For which tests to run:** Use the **test-scope-decision-tree** skill.

**This project:** See table below for area â†’ command. Run `make docker-test` only when Dockerfile/structure/deps changed.

**Run slow tests ONLY if you changed:**

| Area Changed | Command | Duration |
|--------------|---------|----------|
| Whisper integration (`whisper_integration.py`) | `make test-integration-slow` | ~5-10 min |
| Summarization with ML (`summarizer.py`) | `make test-integration-slow` | ~5-10 min |
| Speaker detection (`speaker_detection.py`) | `make test-integration-slow` | ~5-10 min |
| Full workflow with ML (`workflow.py`) | `make test-all-slow` | ~20-30 min |
| E2E tests with ML models | `make test-e2e-slow` | ~15-20 min |

**When NOT to run slow tests:**

- âŒ Only unit test changes
- âŒ Only documentation changes
- âŒ Only configuration changes (that don't affect ML)
- âŒ Code changes that don't touch ML model paths

### Docker testing (CONDITIONAL)

**Run `make docker-test` ONLY if you changed:**

- âœ… Dockerfile â€” any changes to build process
- âœ… Project structure â€” changes to package layout
- âœ… Dependencies â€” changes to `pyproject.toml` (core deps, metadata)
- âœ… Package configuration â€” changes to `[tool.setuptools]`

**Skip for:** Python-only changes, docs, tests, non-Docker config.

## âš¡ Test Efficiency Rules

**For the procedure:** Use the **efficient-pytest-runs** skill.

**This project:** Use make targets for suites; for single-test debug use pytest with `-v --tb=short -ra -rs`. Never run the same suite twice.

## Pytest Markers

### Use These Markers

```python
@pytest.mark.slow              # Tests that take >5s
@pytest.mark.integration       # Tests that use multiple modules
@pytest.mark.e2e              # End-to-end tests with full workflow
@pytest.mark.ml_models        # Tests that load ML models
@pytest.mark.critical_path    # Fast tests that run on PRs
```

### Marker Combinations

```python
# Slow integration test with ML models
@pytest.mark.slow
@pytest.mark.integration
@pytest.mark.ml_models
def test_whisper_transcription():
    pass

# Fast critical path E2E test
@pytest.mark.e2e
@pytest.mark.critical_path
def test_workflow_download_only():
    pass
```

## Test Structure

### Test Naming Convention

```python
# Good - descriptive scenario
def test_fetch_url_retries_on_connection_error():
    pass

def test_sanitize_filename_replaces_invalid_chars():
    pass

# Bad - not descriptive
def test_fetch_url():
    pass

def test_sanitize():
    pass
```

### Test Organization

```text
tests/
â”œâ”€â”€ unit/              # Pure unit tests (no external deps)
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_downloader.py
â”‚   â””â”€â”€ test_filesystem.py
â”œâ”€â”€ integration/       # Multi-module integration tests
â”‚   â”œâ”€â”€ test_whisper_integration.py
â”‚   â”œâ”€â”€ test_summarizer.py
â”‚   â””â”€â”€ test_speaker_detection.py
â””â”€â”€ e2e/              # End-to-end workflow tests
    â”œâ”€â”€ test_workflow_basic.py
    â””â”€â”€ test_workflow_full.py
```

## Mocking Requirements

### Always Mock External Dependencies

```python
from unittest.mock import Mock, patch

# Mock HTTP calls
@patch("podcast_scraper.downloader.requests.Session")
def test_download(mock_session):
    mock_session.get.return_value = Mock(status_code=200, content=b"data")
    # test code

# Mock Whisper
@patch("podcast_scraper.whisper_integration.whisper")
def test_transcribe(mock_whisper):
    mock_whisper.load_model.return_value = Mock()
    # test code

# Mock file I/O (use tempfile)
import tempfile
def test_save_file():
    with tempfile.TemporaryDirectory() as tmpdir:
        # test code
```

### What to Mock

- âœ… HTTP requests (`requests.Session`, `requests.get`)
- âœ… Whisper models (`whisper.load_model`, `whisper.transcribe`)
- âœ… File I/O (use `tempfile.TemporaryDirectory`)
- âœ… spaCy models (mock NER extraction)
- âœ… Time operations (`time.sleep`, `time.time`)
- âœ… OpenAI API calls (when implemented)

## Coverage Requirements

- **Target:** >80% line coverage
- **Focus:** Core business logic (not mocks/fixtures)
- **Check:** `make coverage` generates HTML report in `htmlcov/`

## Running Tests

### Common Commands

```bash
# Fast tests (default for development)
make ci-fast               # No coverage, fastest (~6-10 min)

# Individual test suites
make test-unit            # Unit tests only (~2-5 min)
make test-integration     # All integration tests (~10-15 min)
make test-e2e            # All E2E tests (~20-30 min)

# Slow tests (when needed)
make test-integration-slow  # Slow integration (~5-10 min)
make test-e2e-slow         # Slow E2E (~15-20 min)
make test-all-slow         # All slow tests (~20-30 min)

# Full CI validation
make ci                   # All checks + tests + coverage (~10-15 min)

# Debug specific test
pytest tests/unit/test_config.py::test_config_validation -v -s
pytest -k "test_whisper" -v  # Run tests matching pattern
```

### Parallel Execution

- Tests run in parallel by default (`-n auto`)
- Disable for debugging: `pytest -n 0 -v -s`

## Quick Decision Tree

```text
Changed code?
â”œâ”€ Docs only? â†’ No tests needed
â”œâ”€ Unit tests only? â†’ make ci-fast
â”œâ”€ ML code changed?
â”‚  â”œâ”€ Integration ML? â†’ make ci-fast + make test-integration-slow
â”‚  â”œâ”€ E2E ML? â†’ make ci-fast + make test-e2e-slow
â”‚  â””â”€ Both? â†’ make ci-fast + make test-all-slow
â”œâ”€ Dockerfile/structure? â†’ make ci-fast + make docker-test
â””â”€ No ML? â†’ make ci-fast
```

## Remember

1. **Start with fast tests** â€” catches most issues quickly
2. **Run slow tests conditionally** â€” only when touching ML code
3. **Mock external dependencies** â€” tests must be isolated
4. **Use descriptive test names** â€” `test_<function>_<scenario>`
5. **Target >80% coverage** â€” focus on business logic
6. **Never run the same test suite twice** â€” collect all info in one run
7. **Fix failing tests immediately** â€” never leave tests broken

---

**Version:** 2.0
**Updated:** 2026-02-09
**Source:** Expanded from v1.0 with rules from `.cursorrules` v1.0
