# AI Coding Guidelines for podcast_scraper

## âš ï¸ MANDATORY: READ THIS FIRST âš ï¸

**THIS FILE IS THE PRIMARY SOURCE OF TRUTH FOR ALL AI ACTIONS IN THIS PROJECT.**

## ðŸš¨ START-OF-SESSION CHECKLIST (MANDATORY - DO THIS FIRST)

**Before taking ANY action in this project, you MUST:**

1. âœ… **Read this file** (at minimum, read the CRITICAL RULES section below)
2. âœ… **Acknowledge you've read it** - Say "I've read the AI guidelines" or similar
3. âœ… **Confirm you understand** - The user may ask "Did you read the guidelines?" - Answer honestly
4. âœ… **Reference this file** for all decisions about commits, pushes, and workflows
5. âœ… **CRITICAL: All analysis/plan documents MUST go in `docs/wip/` - NEVER create `docs/analysis/` or any other folder**

**If the user asks "Did you read the guidelines?" or "Check the guidelines first":**

- âœ… **STOP what you're doing**
- âœ… **Read `.ai-coding-guidelines.md` immediately**
- âœ… **Acknowledge what you read**
- âœ… **Then proceed with the task**

**Before taking ANY action, you MUST:**

1. âœ… Read this entire file (especially CRITICAL sections)
2. âœ… Follow ALL rules marked as CRITICAL
3. âœ… Reference this file for all decisions
4. âœ… Check this file when unsure about patterns or workflows

## ðŸ“š LOADING GUIDELINES (OPTIMIZED FOR CONTEXT)

**When the user asks to "load ai coding guidelines" or "load coding guidelines":**

### Default: Load Quick Reference (OPTIMIZED)

1. âœ… **`.ai-coding-guidelines-quick.md`** (~150 lines) - Condensed quick reference with critical rules
2. âœ… **`.ai-coding-guidelines.md`** (this file) - Main guidelines with complete details

**Total: ~2,300 lines instead of ~5,500 lines** (saves ~60% context)

### Load Full Guides On-Demand (When Needed)

**Only load these when working on specific topics:**

- **Code style/formatting work** â†’ Load `docs/guides/DEVELOPMENT_GUIDE.md` (Code Style section)
- **Writing tests** â†’ Load `docs/guides/TESTING_GUIDE.md`
- **Editing markdown** â†’ Load `docs/guides/MARKDOWN_LINTING_GUIDE.md`
- **Cursor model selection** â†’ Load `docs/guides/CURSOR_AI_BEST_PRACTICES_GUIDE.md`
- **Complete reference needed** â†’ Load all 5 files (explicit request)

**Loading pattern:**

```python

# When user says "load ai coding guidelines" or "load coding guidelines":

# 1. Read .ai-coding-guidelines-quick.md (condensed, ~150 lines)
# 2. Read .ai-coding-guidelines.md (main file, ~2,169 lines)
# 3. Acknowledge loaded and summarize key points

# Total: ~2,300 lines (instead of ~5,500 lines)

# For specific topics, load on-demand:
# - "load testing guide" â†’ docs/guides/TESTING_GUIDE.md
# - "load markdown guide" â†’ docs/guides/MARKDOWN_LINTING_GUIDE.md
# - "load cursor guide" â†’ docs/guides/CURSOR_AI_BEST_PRACTICES_GUIDE.md
# - "load development guide" â†’ docs/guides/DEVELOPMENT_GUIDE.md

```text

**CRITICAL RULES (MUST FOLLOW ALWAYS - NO EXCEPTIONS):**

**ðŸš¨ FILE LOCATION RULE - ABSOLUTE PROHIBITION (NO EXCEPTIONS):**

**When creating ANY analysis, plan, review, or WIP document:**

1. âŒ **NEVER create `docs/analysis/` folder** - This folder MUST NOT EXIST
2. âŒ **NEVER create `docs/plan/` folder** - This folder MUST NOT EXIST
3. âŒ **NEVER create analysis files anywhere except `docs/wip/`**
4. âœ… **ALWAYS create analysis/plan/review documents in `docs/wip/` folder**
5. âœ… **If you see yourself typing `docs/analysis/` â†’ STOP and use `docs/wip/` instead**

**Examples of what goes in `docs/wip/`:**
- `docs/wip/critical-path-analysis.md` âœ…
- `docs/wip/episode-length-analysis.md` âœ…
- `docs/wip/e2e-fast-trimming-proposal.md` âœ…
- `docs/wip/integration-fast-trimming-proposal.md` âœ…

**Examples of what is FORBIDDEN:**
- `docs/analysis/critical-path-analysis.md` âŒ **NEVER DO THIS**
- `docs/plan/implementation-plan.md` âŒ **NEVER DO THIS**
- `docs/review/architecture-review.md` âŒ **NEVER DO THIS**

**ðŸš¨ COMMIT WORKFLOW - MANDATORY CHECKLIST (NO EXCEPTIONS):**

1. âŒ **NEVER commit without first showing `git status`**
2. âŒ **NEVER commit without first showing `git diff`**
3. âŒ **NEVER commit without explicit user approval**
4. âŒ **NEVER commit when user said "don't commit" or "wait"**
5. âœ… **ALWAYS show changes BEFORE asking to commit**
6. âœ… **ALWAYS wait for explicit approval (user says "commit", "yes", "go ahead", etc.)**
7. âœ… **ALWAYS get commit message from user OR ask for one**

**ðŸš¨ PR PUSH WORKFLOW - MANDATORY CHECKLIST (NO EXCEPTIONS):**

**CRITICAL: USER APPROVAL REQUIRED BEFORE EVERY PUSH**

1. âŒ **NEVER push to PR without explicit user approval**
2. âŒ **NEVER push without showing `git status` and `git diff` first**
3. âŒ **NEVER push when user said "don't push" or "wait"**
4. âŒ **NEVER push to PR without running `make ci` first**
5. âŒ **NEVER push when `make ci` has failures**
6. âœ… **ALWAYS show `git status` before asking to push**
7. âœ… **ALWAYS show `git diff` or summary of changes before asking to push**
8. âœ… **ALWAYS run `make ci` before pushing to PR (new or updated)**
9. âœ… **ALWAYS fix all CI failures before pushing**
10. âœ… **ALWAYS wait for explicit approval (user says "push", "go ahead", "yes", etc.)**
11. âœ… **ONLY push after steps 6-10 are complete AND user has approved**

**ðŸš¨ GITHUB OPERATIONS - MCP SERVER FIRST (MANDATORY):**

**CRITICAL: Always use MCP GitHub server for GitHub operations, with API as fallback only**

**For ALL GitHub operations (PRs, issues, branches, etc.), follow this priority:**

1. âœ… **ALWAYS use MCP GitHub server tools first** - Preferred method for all GitHub operations
   - Create PRs: `mcp_github_create_pull_request`
   - Read PRs: `mcp_github_pull_request_read`
   - Update PRs: `mcp_github_update_pull_request`
   - Create/update issues: `mcp_github_issue_write`
   - List/search: `mcp_github_list_pull_requests`, `mcp_github_search_issues`, etc.
   - All other GitHub operations via MCP tools

2. âœ… **Use MCP server for:**
   - Creating pull requests
   - Reading PR details, diffs, reviews, comments
   - Updating PR titles, descriptions, labels
   - Creating and updating issues
   - Searching repositories, issues, PRs
   - Managing branches
   - Any GitHub API operation

3. âš ï¸ **Fallback to GitHub API only if:**
   - MCP server is unavailable or returns errors
   - Specific operation not available in MCP server
   - User explicitly requests API usage
   - After attempting MCP server and it fails

4. âŒ **NEVER use GitHub API directly when MCP server is available**
   - Don't use `requests` or `httpx` to call GitHub API
   - Don't use `gh` CLI tool when MCP server can do it
   - Don't use manual GitHub web interface when MCP server can automate it

**Why MCP server first:**
- Better integration with AI workflow
- Consistent authentication handling
- Structured responses and error handling
- No need to manage API tokens or CLI tools
- More reliable and maintainable

**Example workflow:**

```python

# âœ… CORRECT: Use MCP server first

mcp_github_create_pull_request(
    owner="chipi",
    repo="podcast_scraper",
    title="feat: add new feature",
    head="feature-branch",
    base="main"
)

# âŒ WRONG: Don't use API directly
# requests.post("https://api.github.com/repos/chipi/podcast_scraper/pulls", ...)

# âš ï¸ FALLBACK: Only if MCP server fails
# If mcp_github_create_pull_request fails, then consider API or ask user

```

**Purpose:** This document provides comprehensive context and guidelines for AI coding assistants
(Cursor, GitHub Copilot, etc.) working on this project.
Think of this as a project-specific CLAUDE.md - instructions for any AI agentic editor.

**For human contributors**, see [CONTRIBUTING.md](CONTRIBUTING.md) instead.

> **ðŸ“š For detailed technical information**, see [`docs/DEVELOPMENT_GUIDE.md`](docs/DEVELOPMENT_GUIDE.md) which covers:
>
> - Code style guidelines and formatting details
> - Testing requirements and test structure details
> - CI/CD integration details
> - Architecture principles
> - Logging guidelines
> - Documentation standards
> - Markdown linting
> - Environment setup details
>
> This file (`.ai-coding-guidelines.md`) focuses on **AI-specific workflow** and **critical rules** for AI assistants.
> For detailed technical patterns and implementation details, refer to `docs/DEVELOPMENT_GUIDE.md`.

---

## ðŸŽ¯ How Cursor Uses This File

**Cursor automatically reads this file** when you're working in this project. It provides context to AI features like:

- **Composer** (AI code generation)
- **Chat** (AI assistant)
- **Inline edits** (AI-powered code suggestions)

**To maximize effectiveness:**

1. âœ… Keep this file updated when patterns change
2. âœ… Reference specific sections when asking Cursor to implement features
3. âœ… Use clear, actionable language (Cursor reads this as instructions)
4. âœ… Include code examples for common patterns

**Cursor-specific optimizations:**

- Sections are structured for easy semantic search
- Code examples are copy-paste ready
- Decision trees help AI make autonomous choices
- "When to Ask" section prevents unnecessary interruptions

### Cursor Model Selection

**Quick Reference:**

- **Auto** â†’ fast iteration, small/local changes (mechanical work)
- **Manual selection** â†’ planning, debugging, architecture, CI failures (deep reasoning)

**Model Selection Guide:**

- **Fast tasks** (renames, formatting, simple fixes): GPT-5.1 Codex Mini, Sonnet 3.5, Gemini 3 Flash
- **Daily driver** (features, tests, refactors): GPT-5.1 Codex Max, Sonnet 4.5
- **Deep reasoning** (CI debugging, architecture, complex issues): GPT-5.2, Opus 4.5
- **High-risk** (security, releases, breaking changes): GPT-5.1 Codex Max High

**How to Influence Auto:**

- Control scope: small selection â†’ fast model, multiple files/logs â†’ stronger model
- Use reasoning language: "analyze", "root cause", "tradeoffs", "why", "alternatives"
- Split planning and execution: plan in Chat, implement in Inline Chat
- Use Composer for big tasks (biases toward stronger models)

> **Mental Model:** Auto for hands, manual for brain.

**For detailed guidance:** See [`docs/guides/CURSOR_AI_BEST_PRACTICES_GUIDE.md`](docs/guides/CURSOR_AI_BEST_PRACTICES_GUIDE.md)
for comprehensive model selection strategies, project-specific workflows, and prompt templates.

---

## Table of Contents

1. [Project Context](#project-context)
2. [When to Run What](#when-to-run-what)
3. [Code Organization](#code-organization)
4. [Package Import Patterns](#package-import-patterns)
5. [Testing Requirements](#testing-requirements)
6. [Documentation Standards](#documentation-standards)
7. [Common Patterns](#common-patterns)
8. [AI Experiment Pipeline](#ai-experiment-pipeline)
9. [Prompt Management](#prompt-management)
10. [OpenAI Provider Integration](#openai-provider-integration)
11. [Environment Variables & Secrets](#environment-variables--secrets)
12. [Security & Secrets](#security--secrets)
13. [Git Workflow](#git-workflow)
14. [Decision Trees](#decision-trees)
15. [When to Ask](#when-to-ask)

---

## Project Context

### What This Project Does

**podcast_scraper** is a Python tool for downloading podcast transcripts from RSS feeds
with optional Whisper transcription fallback.

**Key capabilities:**

- Download published transcripts from RSS feeds (Podcasting 2.0 namespace)
- Fallback to Whisper transcription for episodes without transcripts
- Automatic speaker detection using spaCy NER
- Episode summarization using local transformer models (BART, LED) or OpenAI API
- Metadata generation (JSON/YAML)
- Multi-threaded downloads
- Screenplay formatting
- Service/daemon mode for automated runs
- **AI Experiment Pipeline** (configuration-driven model evaluation)
- **Prompt Management** (versioned, parameterized prompts)

**Primary use case:** Personal, non-commercial transcript archival for research and study.

### Architecture Overview

**Design:** Modular architecture with clear separation of concerns

**13 core modules:**

1. `cli.py` - Interactive command-line interface
2. `service.py` - Non-interactive service API for daemons
3. `workflow.py` - Pipeline orchestration
4. `config.py` - Configuration model (Pydantic)
5. `rss_parser.py` - RSS feed parsing
6. `downloader.py` - HTTP operations with retry logic
7. `episode_processor.py` - Episode-level processing
8. `filesystem.py` - File system utilities
9. `whisper_integration.py` - Whisper transcription interface
10. `speaker_detection.py` - NER-based speaker extraction
11. `summarizer.py` - Transcript summarization
12. `metadata.py` - Metadata document generation
13. `progress.py` - Progress reporting abstraction

**Future modules (planned):**

- `prompt_store.py` - Prompt management and loading (RFC-017)
- `experiment_config.py` - Experiment configuration models (RFC-015)
- Provider modules (OpenAI, etc.) - Protocol-based provider system (RFC-016)

**Data flow:**

````text
RSS Feed â†’ Parse Episodes â†’ Download/Transcribe â†’ Detect Speakers â†’
Generate Metadata â†’ Summarize â†’ Write Files
```text

- Python 3.10+ (type hints, Pydantic v2)
- Pydantic for configuration validation
- Click for CLI (optional dependency)
- defusedxml for safe XML parsing
- `python-dotenv` for environment variable management

**ML/AI:**

- OpenAI Whisper for transcription
- spaCy for NER (speaker detection)
- PyTorch + transformers for summarization (BART, PEGASUS, LED)
- OpenAI API (planned) for optional providers
- Jinja2 for prompt templating (RFC-017)

**Testing:**

- pytest with unittest.mock
- pytest markers: `@pytest.mark.slow`, `@pytest.mark.integration`
- Coverage target: >80%

**Documentation:**

- MkDocs with Material theme
- mkdocstrings for API docs (auto-generated from docstrings)
- Mermaid for diagrams

**Code Quality:**

- black (formatting, line length: 100)
- isort (import sorting)
- flake8 (linting)
- mypy (type checking)
- bandit (security scanning)

**ðŸš¨ CRITICAL: Write Lint-Valid Code from the Start**

**When writing new code or modifying existing code, ALWAYS consider linting rules from the beginning:**

- âœ… **Write code that passes linting checks immediately** - Don't write code and fix linting errors later
- âœ… **Follow line length limits** - Keep lines under 100 characters (black/flake8 E501)
- âœ… **Follow import organization** - Use isort-compatible import order (stdlib â†’ third-party â†’ local)
- âœ… **Follow naming conventions** - Use snake_case for functions/variables, PascalCase for classes
- âœ… **Remove unused imports** - Don't leave unused imports (flake8 F401)
- âœ… **Remove unused variables** - Don't leave unused variables (flake8 F841)
- âœ… **Follow type hints** - Add type hints to function signatures (mypy compliance)
- âœ… **Follow docstring style** - Use Google-style docstrings for public functions

**Why this matters:**
- Prevents accumulation of linting errors that require bulk fixes
- Saves time by avoiding post-commit linting fixes
- Maintains code quality standards from the start
- Reduces CI failures and rework

**Best practice:** Before finishing any code change, mentally check:
- Are all lines under 100 characters?
- Are imports properly organized?
- Are there any unused imports or variables?
- Do functions have proper type hints and docstrings?

**If you find yourself writing code that will need linting fixes:**
- âœ… **Stop and refactor immediately** - Break long lines, organize imports, remove unused code
- âœ… **Don't defer linting fixes** - Fix issues as you write, not after
- âœ… **Use `make format` and `make lint` frequently** - Catch issues early during development

### Project Structure

```text
podcast_scraper/
â”œâ”€â”€ __init__.py              # Public API exports (lazy loading)
â”œâ”€â”€ cli.py                   # CLI interface
â”œâ”€â”€ service.py               # Service API
â”œâ”€â”€ workflow.py              # Pipeline orchestration
â”œâ”€â”€ config.py                # Configuration model
â”œâ”€â”€ [10 more modules]        # Core functionality
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ docs/                    # MkDocs documentation
â”‚   â”œâ”€â”€ rfc/                 # Technical RFCs
â”‚   â”œâ”€â”€ prd/                 # Product requirements
â”‚   â””â”€â”€ wip/                  # Work in progress docs
â”œâ”€â”€ examples/                # Config examples
â”œâ”€â”€ scripts/                 # Utility scripts (eval, fix_markdown, etc.)
â”œâ”€â”€ prompts/                 # Prompt templates (planned, RFC-017)
â”œâ”€â”€ Makefile                 # Development commands
â”œâ”€â”€ pyproject.toml           # Package metadata
â”œâ”€â”€ pyproject.toml          # Package metadata and dependencies
â””â”€â”€ CONTRIBUTING.md          # Contributor guide
```text
```text

# Step 1: Run fast tests (if not already done)

make test-ci-fast

# Step 2: Run slow tests if changes touch slow test areas (see testing section below)

# make test-integration-slow  # If changed integration code with ML

# make test-e2e-slow          # If changed E2E code with ML

# Step 3: Full CI validation (includes all checks + tests + docs + build)

make ci
```bash

- `make lint` - After adding new functions (flake8)
- `make type` - After changing type hints (mypy)
- `make security` - After changing dependencies (bandit, pip-audit)
- `make docs` - After updating docstrings or docs/
- `make lint-markdown` - After editing markdown files

## ðŸš¨ CRITICAL: Running Tests After Making Changes

**MANDATORY: Always run appropriate tests after making code changes to catch issues early and save time.**

**Default Strategy: Start with fast tests, then run slow tests if needed**

### Step 1: Always Run Fast Tests First (Default)

**After ANY code changes, run fast tests first:**

```bash

# Fast tests (unit + fast integration + fast e2e, excludes slow/ml_models)

# Duration: ~6-10 minutes

# No coverage overhead for faster execution

make test-ci-fast
```text

- âœ… After any code changes (default choice)
- âœ… After bug fixes
- âœ… After adding new features
- âœ… After refactoring
- âœ… Before committing changes
- âœ… Quick validation during development

**Why start here:**
- Fastest feedback (~6-10 min vs ~15-20 min for full suite)
- Catches most issues (unit + fast integration + fast e2e)
- No coverage overhead (faster execution)
- Saves time during development

## Step 2: Run Slow Tests If Changes Touch Slow Test Areas

**After running fast tests, evaluate if slow tests are needed:**

**Run slow tests if you changed code in these areas:**

| Area Changed | Slow Tests to Run | Command |
| -------------- | ------------------ | --------- |
| **Integration tests** (slow/ml_models marked) | Slow integration tests | `make test-integration-slow` |
| **E2E tests** (slow/ml_models marked) | Slow E2E tests | `make test-e2e-slow` |
| **Both integration and E2E** (slow/ml_models) | All slow tests | `make test-all-slow` |
| **Whisper integration** (`whisper_integration.py`) | Slow integration tests | `make test-integration-slow` |
| **Summarization with ML models** (`summarizer.py` with transformers) | Slow integration tests | `make test-integration-slow` |
| **Speaker detection with ML** (`speaker_detection.py` with spaCy) | Slow integration tests | `make test-integration-slow` |
| **Full workflow** (`workflow.py` with ML features) | Slow integration + slow E2E | `make test-all-slow` |
| **E2E workflows** (full pipeline with ML) | Slow E2E tests | `make test-e2e-slow` |

**When to run slow tests:**
- âœ… Changed code that uses ML models (Whisper, transformers, spaCy)
- âœ… Changed integration test code marked with `@pytest.mark.slow` or `@pytest.mark.ml_models`
- âœ… Changed E2E test code marked with `@pytest.mark.slow` or `@pytest.mark.ml_models`
- âœ… Changed core workflow that affects ML model loading/usage
- âœ… Changed configuration that affects ML model selection
- âœ… Before final commit/push (if changes touch slow test areas)

**When NOT to run slow tests:**
- âŒ Only unit test changes
- âŒ Only documentation changes
- âŒ Only configuration file changes (that don't affect ML)
- âŒ Only fast integration/E2E test changes
- âŒ Code changes that don't touch ML model code paths

### Step 3: Run Full Validation Before Push

**Before pushing to PR, run full validation:**

```bash

# Full validation (unit + fast integration + fast e2e, with coverage)

# Duration: ~10-15 minutes

# Includes unified coverage report

make ci
```text

- Formatting checks (black, isort)
- Linting (flake8, markdownlint)
- Type checking (mypy)
- Security (bandit, pip-audit)
- Tests (unit + fast integration + fast e2e, with coverage)
- Documentation build (mkdocs)
- Package build

**Note:** `make ci` runs fast tests only (excludes slow/ml_models). Slow tests run on main branch in CI.

## Decision Tree: Which Tests to Run?

```bash
    â”‚   â”‚   â””â”€ Slow tests pass? â†’ Ready to commit/push
    â”‚   â””â”€ No â†’ Ready to commit/push
    â””â”€ No â†’ Fix issues â†’ Run fast tests again
```text
```bash

# Step 1: Run fast tests

make test-ci-fast

# Step 2: Fast tests pass, no slow test areas touched â†’ Ready!

# (No need to run slow tests)

```bash

make test-ci-fast

# Step 2: Fast tests pass, but changed ML model code â†’ Run slow tests

make test-integration-slow  # If changed integration code

# OR

make test-e2e-slow          # If changed E2E code

# OR

make test-all-slow          # If changed both

# Step 3: All tests pass â†’ Ready to commit/push

```text

# Step 2: Fast tests pass â†’ Ready!

# (Documentation changes don't need slow tests)

```bash

make test-ci-fast

# Step 2: Fast tests pass, but workflow.py affects ML â†’ Run slow tests

make test-all-slow  # Tests both integration and E2E with ML

# Step 3: All tests pass â†’ Ready to commit/push

```text
- Run `make ci` before pushing to PR (full validation)
- Run tests after each significant change (don't wait until the end)

**âŒ DON'T:**
- Don't skip fast tests and jump to slow tests (wastes time)
- Don't run slow tests for unit test changes only
- Don't run all tests (`make test-all`) unless necessary (very slow)
- Don't skip tests before committing (catch issues early)

## Time Savings

**By running fast tests first:**
- Fast tests: ~6-10 minutes
- Slow tests: ~15-30 minutes (only when needed)
- **Total: ~6-10 min (most cases) vs ~20-40 min (if always running all tests)**

**Savings:** 10-30 minutes per development cycle when slow tests aren't needed!

### Utility Scripts

**Available utility scripts in `scripts/` directory:**

- **`fix_markdown.py`** - Automatically fixes common markdown linting issues
  - **When to use:** Before committing markdown files, after bulk documentation edits, when CI fails on markdown linting
  - **Usage:**

    ```bash

```bash

# Fix all markdown files

python scripts/fix_markdown.py

# Fix specific files

python scripts/fix_markdown.py docs/TESTING_STRATEGY.md

# Dry run (see what would be fixed)

python scripts/fix_markdown.py --dry-run

```python
- **What it fixes:** Table separators (MD060), trailing spaces (MD009), blank lines around
  lists (MD032), code block languages (MD040)

- **See:** `scripts/README.md` for full documentation

- **`check_unit_test_imports.py`** - Verifies unit tests can import without ML dependencies
- **`eval_cleaning.py`** - Evaluates transcript cleaning quality
- **`eval_summaries.py`** - Evaluates summarization quality using ROUGE metrics

**Best practice:** Run `python scripts/fix_markdown.py` before committing markdown files to catch common issues early.

## What CI Runs Automatically

> **See also:** [`docs/CI_CD.md`](docs/CI_CD.md) for complete CI/CD pipeline documentation with visualizations.

**On every push to PR (5 parallel workflows):**

1. **Python App Workflow** (Lint Job, 2-3 min):
   - Black/isort formatting checks
   - flake8 linting
   - markdownlint
   - mypy type checking
   - bandit + pip-audit security

2. **Python App Workflow** (Test Job, 10-15 min):
   - Full pytest suite with coverage

3. **Docs Workflow** (3-5 min):
   - mkdocs build --strict
   - API docs generation

4. **Docker Workflow** (on Dockerfile/project structure changes):
   - **When to test:** Only when Dockerfile, pyproject.toml structure, or package layout changes
   - **How to test:** Run `make docker-test` locally before pushing to PR
   - **What it does:** Builds Docker image and runs basic validation
   - **Why:** Catches Docker build failures before CI runs (Docker builds are slow in CI)

5. **Snyk Workflow** (weekly + on push):
   - Security vulnerability scanning

**Additional workflows:**

- **CodeQL Security** (weekly + on push): Python & Actions security scanning
- **Docs Deployment** (on main): Build â†’ Deploy to GitHub Pages

**When CI fails:**

1. Read the error message carefully
2. Run `make ci` locally to reproduce
3. Fix the issue (use `make format` for formatting issues)
4. Test locally again
5. Push the fix

**Prevent CI failures:**

```bash

make install-hooks    # Catch issues before commit!

```text
- âŒ Docker builds (unless working on Docker specifically OR before pushing Docker-related changes to PR)
- âŒ Deployment commands (GitHub Actions handles this)

**Use CI for:**

- Full test suite on every platform
- Documentation deployment
- Release builds

---

## Code Organization

### When to Create New Files

**Create a new module when:**

- Implementing a new major feature (>500 lines)
- Feature has distinct responsibility (SRP)
- Feature can be tested independently
- Example: Adding PostgreSQL export â†’ create `export.py`

**Modify existing files when:**

- Fixing bugs in existing functionality
- Enhancing existing features (< 200 lines added)
- Refactoring within same module
- Example: Improving Whisper model selection â†’ modify `whisper_integration.py`

**Don't create:**

- Helper modules with only 1-2 functions (add to appropriate existing module)
- Duplicate functionality (search codebase first)
- Temporary files (use proper temporary directories)
- **`docs/analysis/` folder or any files in it** - All analysis/plan documents MUST go in `docs/wip/` (see Document Location Rules below)

### Module Boundaries (STRICT)

**Respect these boundaries** - don't mix concerns:

| Module | Responsibility | What to AVOID |
| ------ | --------------- | ------------- |
| `cli.py` | CLI interface only | Business logic, HTTP calls, file I/O |
| `service.py` | Service API, structured results | CLI interaction, user prompts |
| `workflow.py` | Orchestration only | HTTP details, file parsing, direct I/O |
| `config.py` | Configuration model | Business logic, side effects |
| `downloader.py` | HTTP operations only | Parsing, business logic |
| `filesystem.py` | File system utilities | HTTP, parsing, business logic |
| `rss_parser.py` | RSS parsing, Episode creation | HTTP, file I/O, workflow |
| `episode_processor.py` | Episode-level processing | CLI interaction, orchestration |
| `whisper_integration.py` | Whisper interface | HTTP, RSS parsing |
| `speaker_detection.py` | NER extraction | HTTP, file I/O |
| `summarizer.py` | Summarization | Episode processing, HTTP |
| `metadata.py` | Metadata generation | HTTP, RSS parsing |
| `progress.py` | Progress abstraction | Business logic |

**If you're about to:**

- Add HTTP calls to `cli.py` â†’ âŒ Use `downloader.py` instead
- Add business logic to `config.py` â†’ âŒ Use `workflow.py` or appropriate module
- Add CLI prompts to `service.py` â†’ âŒ Service is non-interactive

### File Naming Conventions

**Python modules:**

- Use `snake_case.py`
- Be descriptive: `speaker_detection.py` not `speakers.py`
- Avoid generic names: `utils.py`, `helpers.py`

**Test files:**

- Mirror structure: `test_<module>.py`
- Example: `test_speaker_detection.py` tests `speaker_detection.py`

**Documentation:**

- Use `UPPER_CASE.md` for top-level docs: `README.md`, `CONTRIBUTING.md`
- Use descriptive names for guides: `TESTING_STRATEGY.md`
- PRD/RFC format: `PRD-NNN-title.md`, `RFC-NNN-title.md`

---

## Package Import Patterns

### Lazy Loading Pattern (CRITICAL)

**The `__init__.py` uses lazy loading** to prevent circular imports:

```python

# __init__.py uses __getattr__ for lazy loading

from podcast_scraper import cli, service  # âœ… Works (lazy loaded)
import podcast_scraper.cli as cli         # âœ… Also works

```python
- Maintains backward compatibility

**When adding new lazy-loaded modules:**

1. Add to `__getattr__` in `__init__.py`
2. Add to `_import_cache` for caching
3. Update `__all__` if needed (but note that lazy-loaded modules aren't in `__all__`)

**Example from `__init__.py`:**

```python

_import_cache: dict[str, object] = {}

def __getattr__(name: str):
    if name in _import_cache:
        return _import_cache[name]

    if name == "cli":
        import importlib
        _cli = importlib.import_module(f"{__name__}.cli")
        _import_cache[name] = _cli
        return _cli

    # ... similar for service

    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")

```python
import os
from pathlib import Path
from typing import Optional, List, Dict

# Third-party (group 2)

import requests
from pydantic import BaseModel

# Local (group 3)

from podcast_scraper import config
from podcast_scraper.models import Episode
```python

@patch("podcast_scraper.downloader.requests.Session")
def test_fetch_url_with_retry(self, mock_session):
    """Test that fetch_url retries on network failure."""
    mock_session.get.side_effect = [
        requests.ConnectionError("Network error"),
        MockHTTPResponse(content="Success", status_code=200)
    ]
    result = fetch_url("https://example.com")
    self.assertEqual(result, "Success")

```python
    """Happy path."""
    pass

def test_sanitize_filename_invalid_chars(self):
    """Error case."""
    pass
```python

    pass

# Bad

def test_config(self):
    pass

```text
- File I/O (use `tempfile.TemporaryDirectory`)
- spaCy models (mock NER extraction)
- Time-based operations (`time.sleep()`)
- OpenAI API calls (when implementing OpenAI providers)

**Example:**

```python

@patch("podcast_scraper.whisper_integration.whisper")
def test_transcription(self, mock_whisper):
    mock_whisper.load_model.return_value = Mock()
    mock_whisper.transcribe.return_value = {"text": "Test"}

    # ... test code ...

```text
```text

- New user-facing features
- Significant functionality additions
- Changes affecting user workflows

**Template:** `docs/prd/PRD-NNN-title.md`

**Examples:**

- PRD-004: Metadata Generation
- PRD-005: Episode Summarization
- PRD-006: OpenAI Provider Integration
- PRD-007: AI Experiment Pipeline

**Structure:**

```markdown

# PRD-NNN: Feature Name

## Problem

[What problem does this solve?]

## Goals

[What are we trying to achieve?]

## Non-Goals

[What are we explicitly NOT doing?]

## Solution

[Proposed solution]

## Success Criteria

[How do we know it works?]
```text

- Architectural changes
- Breaking API changes
- Design decisions needing discussion
- Technical implementation approaches

**Template:** `docs/rfc/RFC-NNN-title.md`

**Examples:**

- RFC-010: Speaker Name Detection
- RFC-012: Episode Summarization
- RFC-013: OpenAI Provider Implementation
- RFC-015: AI Experiment Pipeline
- RFC-016: Modularization for AI Experiments
- RFC-017: Prompt Management

**Structure:**

```markdown

# RFC-NNN: Feature Name

## Background

[Context and motivation]

## Proposal

[Detailed technical proposal]

## Alternatives Considered

[Other approaches and why not chosen]

## Implementation

[How to build this]

## Testing

[How to test this]
```python

**How to Use Templates:**

1. **Copy the template** from the appropriate folder:
   - For PRDs: Copy `docs/prd/PRD_TEMPLATE.md`
   - For RFCs: Copy `docs/rfc/RFC_TEMPLATE.md`

2. **Rename the file** with the appropriate number and feature name:
   - PRD: `PRD-NNN-feature-name.md` (e.g., `PRD-008-new-feature.md`)
   - RFC: `RFC-NNN-feature-name.md` (e.g., `RFC-028-new-feature.md`)
   - **Note**: Use the next available number (check `docs/prd/index.md` and `docs/rfc/index.md`)

3. **Fill in the placeholders**:
   - Replace `[Feature Name]` with the actual feature name
   - Replace `[Description]` placeholders with actual content
   - Replace `[PRD-XXX]` and `[RFC-XXX]` with actual related document numbers
   - Remove sections that don't apply to your feature

4. **Follow the template structure**:
   - Keep all relevant sections from the template
   - Maintain the same formatting and organization
   - Use the same hierarchical numbering (FR1, FR1.1, etc. for PRDs)

5. **Update index files**:
   - Add the new PRD to `docs/prd/index.md`
   - Add the new RFC to `docs/rfc/index.md`
   - Include status, related PRDs/RFCs, and description

6. **Review and refine**:
   - Ensure all placeholders are replaced
   - Verify all sections are complete
   - Check that links to related documents are correct

**Example Workflow:**

```bash

# Create a new PRD

cp docs/prd/PRD_TEMPLATE.md docs/prd/PRD-008-feature-name.md

# Edit PRD-008-feature-name.md, fill in all placeholders

# Update docs/prd/index.md to include the new PRD

# Create a new RFC

cp docs/rfc/RFC_TEMPLATE.md docs/rfc/RFC-028-feature-name.md

# Edit RFC-028-feature-name.md, fill in all placeholders

# Update docs/rfc/index.md to include the new RFC

```python

- âœ… **Always start from the template** - Don't create PRDs/RFCs from scratch
- âœ… **Check existing numbers** - Use the next available number in the sequence
- âœ… **Remove unused sections** - If a section doesn't apply, remove it rather than leaving placeholders
- âœ… **Update index files** - Always add new documents to the index
- âœ… **Follow naming conventions** - Use lowercase with hyphens for filenames

**You can skip documentation for:**

- âœ… Bug fixes (just fix it)
- âœ… Small enhancements (< 100 lines)
- âœ… Internal refactoring (no API changes)
- âœ… Documentation updates
- âœ… Test improvements
- âœ… Performance optimizations (if localized)

**Rule of thumb:** If it takes longer to document than implement, skip the doc.

## Document Location Rules

**ðŸš¨ CRITICAL: Where to Create Analysis and Plan Documents**

**ðŸš¨ ABSOLUTE RULE: All analysis or plan documents MUST be created in `docs/wip/` folder:**

- âœ… **Analysis documents** (code analysis, test pyramid analysis, performance analysis, critical path analysis, episode length analysis, etc.) â†’ **`docs/wip/`**
- âœ… **Plan documents** (implementation plans, refactoring plans, migration plans, trimming proposals, etc.) â†’ **`docs/wip/`**
- âœ… **Work-in-progress documentation** (draft RFCs, experimental designs, etc.) â†’ **`docs/wip/`**
- âœ… **Review documents** (code reviews, architecture reviews, etc.) â†’ **`docs/wip/`**
- âœ… **Summary documents** (test fixture summaries, trimming summaries, etc.) â†’ **`docs/wip/`**

**There is NO exception to this rule. If it's analysis, plan, review, or WIP â†’ it goes in `docs/wip/`.**

**Examples:**

- `docs/wip/TEST_PYRAMID_ANALYSIS.md` - Analysis of test structure
- `docs/wip/IMPLEMENTATION_PLAN.md` - Plan for implementing a feature
- `docs/wip/ARCHITECTURE_REVIEW.md` - Architecture review notes
- `docs/wip/REFACTORING_PLAN.md` - Plan for refactoring code

**ðŸš¨ ABSOLUTELY FORBIDDEN - DO NOT CREATE THESE FOLDERS OR FILES:**

- âŒ **`docs/analysis/`** - THIS FOLDER MUST NEVER EXIST. All analysis goes in `docs/wip/`
- âŒ **`docs/plan/`** - THIS FOLDER MUST NEVER EXIST. All plans go in `docs/wip/`
- âŒ Root directory
- âŒ `docs/` root (without subdirectory)
- âŒ `docs/rfc/` (only for formal RFCs)
- âŒ `docs/prd/` (only for formal PRDs)

**If you see yourself about to create `docs/analysis/` or any file in it:**
- âŒ **STOP IMMEDIATELY**
- âœ… **Create the file in `docs/wip/` instead**
- âœ… **Remember: Analysis = WIP, Plans = WIP, Reviews = WIP**

**Rationale:**

- `docs/wip/` is specifically for work-in-progress, analysis, and planning documents
- Keeps the main documentation structure clean
- Makes it clear these are temporary/working documents
- Easy to find and organize all analysis/planning work in one place

**When a document matures:**

- If an analysis becomes a formal RFC â†’ Move to `docs/rfc/` and follow RFC format
- If a plan becomes a formal PRD â†’ Move to `docs/prd/` and follow PRD format
- If it's no longer needed â†’ Delete or archive

### Markdown Best Practices

**ðŸš¨ CRITICAL: Follow These Patterns to Prevent Linting Errors**

**Important:** The project uses `.markdownlint.json` with `"default": true`, which means **ALL default markdownlint rules are enabled** unless explicitly disabled. The pre-commit hook checks **all enabled rules**, not just the ones mentioned in documentation.

**When creating or editing markdown files, proactively follow these patterns to avoid common linting issues:**

#### 1. Blank Lines Around Lists (MD032)

**Always add blank lines before and after lists:**

```markdown
âœ… Good:
This is a paragraph.

- List item 1
- List item 2

This is another paragraph.

âŒ Bad:
This is a paragraph.

- List item 1
- List item 2
This is another paragraph.

```text

#### 2. No Trailing Spaces (MD009)

**Never leave trailing whitespace at the end of lines:**

```markdown
âœ… Good:
This is a line with no trailing space.

âŒ Bad:
This is a line with trailing space.
```text

- âœ… Always trim trailing whitespace
- âœ… Use your editor's "trim trailing whitespace" feature
- âœ… Run `python scripts/fix_markdown.py` before committing

#### 3. Table Formatting (MD060)

**Tables must have consistent spacing around pipes:**

```markdown
âœ… Good (compact style):
| Header | Column2 | Column3 |
| -------- | --------- | --------- |
| Value1 | Value2  | Value3  |

âŒ Bad (no spaces around pipes in separator):
| Header | Column2 | Column3 |
| -------- | --------- | --------- |
| Value1 | Value2  | Value3  |

âŒ Bad (inconsistent spacing):
| Header  | Column2 | Column3 |
| -------- | ------- | ------- |
| Value1 | Value2 | Value3 |
```yaml

- âœ… Use spaces around pipes in all rows: `| Column |`
- âœ… Separator row should match header row spacing: `|--------|`
- âœ… For complex tables, use Python to generate exact alignment (see `docs/guides/MARKDOWN_LINTING_GUIDE.md`)
- âœ… Run `python scripts/fix_markdown.py` to auto-fix table separators

#### 4. Code Block Language Specifiers (MD040)

**Always specify language for code blocks:**

âœ… Good:
- Use ` ```python` for Python code
- Use ` ```bash` for shell scripts
- Use ` ```yaml` for YAML files
- Use ` ```json` for JSON data

âŒ Bad:
- Using ` ``` ` without language (just three backticks)
- Omitting language specifier

**Example:**

```text
âœ… Good:
```python

def example():
    pass

```text
- âœ… Use `markdown` for markdown examples
- âœ… Common languages: `python`, `bash`, `yaml`, `json`, `markdown`, `text`

#### 5. No Multiple Blank Lines (MD012)

**Avoid consecutive blank lines:**

```markdown

âœ… Good:
Paragraph 1.

Paragraph 2.

âŒ Bad:
Paragraph 1.

Paragraph 2.

```text
- âœ… Run `python scripts/fix_markdown.py` to auto-fix multiple blank lines

#### 6. General Markdown Formatting

**Additional best practices:**

- âœ… **Headings**: Use proper heading hierarchy (H1 â†’ H2 â†’ H3, don't skip levels)
- âœ… **Lists**: Use consistent list markers (`-` for unordered, `1.` for ordered)
- âœ… **Links**: Use descriptive link text: `[Link Text](url)` not `[url](url)`
- âœ… **Code**: Use backticks for inline code: `` `code` `` not `'code'`
- âœ… **Emphasis**: Use `**bold**` and `*italic*` consistently

#### Workflow for Markdown Files

**Before committing markdown files:**

<!-- markdownlint-disable MD029 -->

1. âœ… **Write markdown following the patterns above**

2. âœ… **Run `python scripts/fix_markdown.py`** to auto-fix common issues:

   ```bash

   # Fix all markdown files

   python scripts/fix_markdown.py

   # Fix specific files

   python scripts/fix_markdown.py docs/TESTING_STRATEGY.md

   # Dry run (see what would be fixed)

   python scripts/fix_markdown.py --dry-run

   ```

3. âœ… **Self-check before finishing** - Scan for: (a) one H1 only, (b) blank line after headings,
   (c) no trailing spaces, (d) list indentation consistent, (e) code fences have language tags

4. âœ… **Verify with `make lint-markdown`** if markdownlint is installed

5. âœ… **MANDATORY: Run `make docs`** to validate docs build correctly (catches broken links,
   missing nav entries, autorefs issues)

6. âœ… **Review changes** before committing

<!-- markdownlint-enable MD029 -->

**What `fix_markdown.py` fixes automatically:**

- Table separator formatting (MD060)
- Trailing spaces (MD009)
- Blank lines around lists (MD032)
- Code block language specifiers (MD040) - when detectable

**See also:**

- `docs/guides/MARKDOWN_LINTING_GUIDE.md` - **Markdown style and linting guide** (style rules,
  linting practices, tools, workflows)

- `scripts/fix_markdown.py` - Automated fixer script
- `scripts/README.md` - Script documentation

### Always Update

**Update these files when:**

| File                       | When to Update                                       |
| -------------------------- | ---------------------------------------------------- |
| `README.md`                | CLI flags change, new features, installation changes |
| `docs/ARCHITECTURE.md`     | Module changes, data flow changes, design decisions  |
| `docs/TESTING_STRATEGY.md` | Testing approach changes, new test infrastructure    |
| `docs/api/`                | Public API changes (auto-generated from docstrings)  |

### âš ï¸ CRITICAL: Check `mkdocs.yml` and Links Before Pushing Documentation Changes

**MANDATORY CHECKLIST when adding, moving, or deleting documentation files:**

- [ ] **New files added?** â†’ Add to `nav` configuration in `mkdocs.yml`
- [ ] **Files moved?** â†’ Update path in `nav` configuration
- [ ] **Files deleted?** â†’ Remove from `nav` configuration
- [ ] **Links updated?** â†’ Use relative paths (e.g., `rfc/RFC-019.md` not `docs/rfc/RFC-019.md`)
- [ ] **All links verified?** â†’ Check that all internal links point to existing files
- [ ] **No broken links?** â†’ Run `make docs` to catch broken links before CI
- [ ] **Test locally?** â†’ Run `make docs` to verify build succeeds

**Why this matters:**

- Missing files in `nav` â†’ CI will fail with warnings
- Broken links â†’ CI will fail with errors (~3-5 min wasted per build)
- Wrong path format â†’ Links won't work in generated docs
- **Fixing locally takes seconds vs. waiting for CI to fail**

**Always check `mkdocs.yml` and verify all links before committing documentation changes!**
| `CONTRIBUTING.md` | Development workflow changes, tool changes |
| `.ai-coding-guidelines.md` | Patterns change, new guidelines needed |
| `docs/index.md`, `docs/rfc/index.md`, `docs/prd/index.md` | New RFCs/PRDs added |

### Release Notes - Historical Accuracy

**ðŸš¨ CRITICAL: Do NOT modify historical release notes**

**Rule:** Never update release notes in `docs/releases/RELEASE_v*.md` for software versions that
have already been shipped, unless the user explicitly asks you to do so.

**Why:** Release notes are historical documents that reflect what was actually shipped at that time.
Modifying them retroactively would:

- Misrepresent what was actually in those releases
- Confuse users who reference historical documentation
- Break the historical record

**What this means:**

- âœ… You CAN update current/upcoming release notes (draft releases)
- âŒ You CANNOT update past release notes (already shipped versions)
- âœ… You CAN update other documentation (README, guides, etc.) to reflect current state
- âŒ You CANNOT "fix" historical release notes to match current codebase

**Examples:**

- âŒ Don't update `RELEASE_v2.3.1.md` to remove `requirements.txt` references (it was there when v2.3.1 shipped)
- âœ… You can update `README.md` to remove `requirements.txt` references (current documentation)
- âŒ Don't change dependency lists in old release notes
- âœ… You can update current documentation to reflect new dependency management

**Exception:** Only modify historical release notes if the user explicitly requests it
(e.g., "update RELEASE_v2.3.1.md to fix a typo").

### Docstring Requirements

**All public functions need docstrings:**

````python

def run_pipeline(cfg: Config) -> Tuple[int, str]:
    """Execute the main podcast scraping pipeline.

    This orchestrates the complete workflow from RSS feed fetching
    to transcript generation and optional metadata/summarization.

    Args:
        cfg: Configuration object with all pipeline settings.

    Returns:
        Tuple[int, str]: (count, summary) where count is episodes
            processed and summary is human-readable message.

    Raises:
        ValueError: If RSS URL is invalid.
        RuntimeError: If output cleanup fails.

    Example:

```text
        >>> cfg = Config(rss="https://example.com/feed.xml")
        >>> count, summary = run_pipeline(cfg)
        >>> print(f"Processed {count} episodes")
    """
```

# Good - centralized configuration

cfg = Config(
    rss="https://example.com/feed.xml",
    transcribe_missing=True,
    workers=8
)
run_pipeline(cfg)

# Bad - scattered parameters

fetch_rss(url, timeout=30)
download(episodes, workers=8)
transcribe(jobs, model="base")

```text

1. Add field to `Config` model in `config.py`
2. Add CLI argument in `cli.py`
3. Document in README options section
4. Update `examples/config.example.json` and `examples/config.example.yaml`

## Error Handling Pattern

**Recoverable errors - log and continue:**

```python

try:
    transcript = download_transcript(url)
except requests.RequestException as e:
    logger.warning(f"Failed to download: {e}")
    return None  # Continue with other episodes

```text

    WHISPER_AVAILABLE = False
    logger.warning("Whisper not available")

```text

    for episode in episodes:
        process(episode)
        pbar.update(1)

# Bad

from tqdm import tqdm
for episode in tqdm(episodes):
    process(episode)

```python

    """Lazy load Whisper library."""
    global _whisper
    if _whisper is None:
        try:
            import whisper
            _whisper = whisper
        except ImportError:
            raise ImportError(
                "Whisper not installed. "
                "Install: pip install openai-whisper"
            )
    return _whisper

# Usage

def transcribe(audio_path):
    whisper = get_whisper()
    model = whisper.load_model("base")

```text

    # ...

```
# Good - structured logging with context

logger.info(f"Processing episode {episode.number}: {episode.title}")
logger.warning(f"Failed to download transcript for {episode.number}: {error}")
logger.error(f"Pipeline failed: {error}", exc_info=True)

# Bad - print statements

print("Processing episode")
print("Error:", error)

```python

- **Configuration-Driven**: Experiments defined in YAML configs
- **Separation of Generation from Scoring**: Generate predictions first, compute metrics separately
- **Two-Layer CI/CD**: Fast smoke tests (CI) + full evaluation pipeline (nightly/on-demand)
- **Test Pipeline Analogy**: Treat model evaluation like unit/integration tests

## Experiment Structure

**Example experiment config:**

```yaml

# experiments/summarization_openai_long_v1.yaml

id: "summarization_openai_long_v1"
task: "summarization"

backend:
  type: "openai"
  model: "gpt-4o-mini"

prompts:
  system: "summarization/system_v1"
  user: "summarization/long_v1"
  params:
    paragraphs_min: 3
    paragraphs_max: 6

data:
  episodes_glob: "data/eval/episodes/ep*/transcript.txt"
  id_from: "parent_dir"

params:
  max_output_tokens: 900

```text

- Move gold data to `data/eval/episodes/`
- Establish baseline results

**Phase 2: Generic Runner**

- `scripts/run_experiment.py` - Load config, call backend, save predictions
- `podcast_scraper/experiment_config.py` - Pydantic models for configs

**Phase 3: CI Smoke Tests (Layer A)**

- Fast tests on subset of episodes
- Assert basic metrics (ROUGE-L > threshold)

**Phase 4: Full Eval Pipeline (Layer B)**

- Nightly/on-demand full evaluation
- Run all experiment configs
- Generate comparison reports

**Phase 5: Comparison Tooling**

- Excel workbook generation
- Side-by-side metric comparison

**See:** `docs/rfc/RFC-015-ai-experiment-pipeline.md` and `docs/prd/PRD-007-ai-experiment-pipeline.md`

---

## Prompt Management

### Overview

**Prompt Management** (RFC-017) treats prompts as first-class, versioned assets with optional templating.

**Key Principles:**

- Prompts are **provider-specific concerns** (not part of core protocol)
- File-based organization with explicit versioning
- Jinja2 templating for parameterization
- SHA256 hashing for reproducibility

### Prompt Directory Structure

```text

prompts/
  summarization/
    system_v1.j2
    long_v1.j2
    long_v2_more_narrative.j2
  ner/
    system_ner_v1.j2
    guest_host_v1.j2

```text

- Aim for {{ paragraphs_min }}â€“{{ paragraphs_max }} paragraphs.
- Focus on key decisions, arguments, and lessons.
- Ignore sponsorships, ads, and housekeeping.
- Do not use quotes or speaker names.
- Do not invent information not implied by the transcript.

```markdown

### Using Prompts

**In application code (OpenAI providers):**

```python

from podcast_scraper.prompt_store import render_prompt, get_prompt_metadata

system_prompt = render_prompt("summarization/system_v1")
user_prompt = render_prompt(
    "summarization/long_v1",
    paragraphs_min=3,
    paragraphs_max=6
)

# Track prompt metadata for reproducibility

metadata = get_prompt_metadata("summarization/long_v1", {"paragraphs_min": 3})

```yaml
- **Protocol-Based**: Providers implement protocols (RFC-016)
- **Backward Compatible**: Default providers (local) unchanged
- **Per-Capability Selection**: Can mix local and OpenAI providers
- **Secure API Key Management**: Environment variables, never in code

## Provider Architecture

**After modularization:**

```text

podcast_scraper/
â”œâ”€â”€ speaker_detectors/
â”‚   â”œâ”€â”€ base.py              # SpeakerDetector protocol
â”‚   â”œâ”€â”€ factory.py           # Factory (selects provider)
â”‚   â”œâ”€â”€ ner_detector.py      # Local NER provider (existing)
â”‚   â””â”€â”€ openai_detector.py   # NEW: OpenAI provider
â”œâ”€â”€ transcription/
â”‚   â”œâ”€â”€ base.py              # TranscriptionProvider protocol
â”‚   â”œâ”€â”€ factory.py           # Factory
â”‚   â”œâ”€â”€ whisper_provider.py  # Local Whisper provider
â”‚   â””â”€â”€ openai_provider.py   # NEW: OpenAI Whisper API
â”œâ”€â”€ summarization/
â”‚   â”œâ”€â”€ base.py              # SummarizationProvider protocol
â”‚   â”œâ”€â”€ factory.py           # Factory
â”‚   â”œâ”€â”€ local_provider.py    # Local transformers provider
â”‚   â””â”€â”€ openai_provider.py   # NEW: OpenAI GPT provider

```text
**Implementation in `config.py`:**

```python

from dotenv import load_dotenv
import os

# Load .env file automatically (if present)

load_dotenv()

class Config(BaseModel):

    # ... other fields ...

    openai_api_key: Optional[str] = Field(
        default=None,
        description="OpenAI API key (or set OPENAI_API_KEY env var)"
    )

    @validator("openai_api_key", pre=True, always=True)
    def resolve_openai_api_key(cls, v):

```python
        """Resolve API key from config field, env var, or .env file."""
```javascript

        # Priority: config field > env var > .env file (already loaded)

```
3. `.env` file (loaded by `python-dotenv`)

**Security:**

- âœ… `.env` files are in `.gitignore`
- âœ… Never commit `.env` files
- âœ… Document required env vars in `README.md` and `CONTRIBUTING.md`
- âœ… Use `examples/.env.example` as template

**See:** `docs/rfc/RFC-013-openai-provider-implementation.md` section "API Key Management"

---

## Security & Secrets

### NEVER Commit

**Never add to git:**

- âŒ API keys or tokens
- âŒ Passwords or credentials
- âŒ Personal data
- âŒ Real RSS feed URLs in tests (use example.com)
- âŒ Private configuration files
- âŒ `.env` files with secrets

### Security Practices

**Input validation:**

```python

# Validate user inputs

if not isinstance(cfg.workers, int) or cfg.workers < 1:
    raise ValueError(f"Invalid workers: {cfg.workers}")

# Sanitize filenames

safe_name = sanitize_filename(episode.title)

# Check paths are within expected directory

if not output_path.is_relative_to(base_dir):
    raise ValueError(f"Path outside output dir: {output_path}")

```python

2. âœ… **Ensure the branch contains ONLY new commits** - No old/unrelated commits
3. âœ… **Start from a clean state** - Branch should be based on the latest target branch

**ðŸš¨ BRANCH CREATION CHECKLIST - MANDATORY BEFORE CREATING ANY BRANCH:**

**CRITICAL: Always check for uncommitted changes before creating a new branch.**

**Step 1: Check Current State**
```bash

git status

```
**What to look for:**
- âŒ If you see "Changes not staged for commit" â†’ You have uncommitted changes
- âŒ If you see "Untracked files" â†’ You have new files
- âœ… If you see "nothing to commit, working tree clean" â†’ You're good to go!

**Step 2: Handle Uncommitted Changes (if any)**

**Option A: Commit to Current Branch** (if changes belong to current work)
```bash

git add .
git commit -m "your message"

```
**Option B: Stash for Later** (if you want to save but not commit)
```bash

git stash

# Later: git stash pop

```
**Option C: Discard Changes** (if not needed)
```bash

git checkout .

# Or for specific files:

git checkout -- path/to/file

```
**Quick One-Liner Check:**
```bash

git status --porcelain

```python
**If you see any output, handle it first!**

**What happens if you don't follow this:**
- âŒ Uncommitted changes from previous work get included in your new branch
- âŒ Your commit will show more files than you actually changed
- âŒ PR will show confusing diffs with unrelated changes
- âŒ Harder to review and understand what actually changed

**Required workflow for creating PR branches:**

```bash

# Step 1: Check for uncommitted changes (MANDATORY)

git status --porcelain

# If output is not empty, handle changes first (commit, stash, or discard)

# Step 2: Ensure you're on the target branch and it's up to date

git checkout main
git pull origin main

# Step 3: Create a new branch from the target branch (clean state)

git checkout -b feature/new-feature-name

# OR if branch already exists locally but has old commits:

git checkout feature/new-feature-name
git reset --hard origin/main  # WARNING: This discards local changes!

# Step 3: Make your changes and commit them

# [Make code changes]

git add .
git commit -m "feat: add new feature"

# Step 4: Verify branch is clean (only new commits)

git log --oneline origin/main..HEAD

# Should show ONLY commits you want in the PR

# Step 5: Push the new branch

git push -u origin feature/new-feature-name

```python

- âœ… Branch contains ONLY commits related to this PR
- âœ… No merge commits from other branches
- âœ… No old commits that were already merged
- âœ… No WIP commits that should be squashed

**How to verify your branch is clean:**

```bash

# Check what commits are in your branch but not in main

git log --oneline origin/main..HEAD

# Should show only commits you want in the PR

# If you see old/unrelated commits, the branch is NOT clean

```bash

# Cherry-pick only the commits you want:

git cherry-pick <commit-hash-1>
git cherry-pick <commit-hash-2>

# Option 2: Reset branch to main (WARNING: Discards local changes)

git checkout feature/existing-branch
git reset --hard origin/main

# Then recommit your changes

```python

- âŒ Branch contains old commits that are already merged
- âŒ Branch has commits from other features/PRs
- âŒ Branch is based on an outdated version of main
- âŒ Branch has merge commits from other branches (unless intentional)

**Why this matters:**

- Clean PRs are easier to review
- Reduces merge conflicts
- Makes git history cleaner
- Prevents accidentally including unrelated changes
- Makes it easier to identify what changed in this PR

## CRITICAL: Always Show Changes and Get Approval Before Committing

**ðŸš¨ MANDATORY CHECKLIST - NO EXCEPTIONS - FOLLOW THIS EXACT SEQUENCE:**

**NEVER automatically commit changes without user approval.**

**Required workflow (MUST FOLLOW IN ORDER):**

1. âœ… Make code changes
2. âœ… **If editing markdown files:** Run `make fix-md` (or `python scripts/fix_markdown.py`) to fix common linting issues
3. âœ… **MANDATORY: Self-check markdown files** (if any were edited):
   - Scan for: (a) one H1 only, (b) blank line after headings, (c) no trailing spaces, (d) list indentation consistent, (e) code fences have language tags
   - Run `make lint-markdown` to verify
4. âœ… **MANDATORY: Run `git status`** - Show user what files changed
5. âœ… **MANDATORY: Run `git diff`** - Show user the actual changes (for each modified file)
6. âœ… **MANDATORY: Wait for explicit user approval** - User must explicitly say "commit", "yes", "go ahead", etc.
7. âœ… **MANDATORY: Get commit message** - User provides message OR you ask "What commit message should I use?"
8. âœ… **THEN commit** - Only after steps 3-7 are complete

**âš ï¸ CRITICAL: Steps 2-7 are MANDATORY. Do NOT skip any step. Do NOT assume approval.**

**What to show:**

- List of changed files (`git status`)
- Diff of changes (`git diff` or `git diff <file>`)
- Summary of what was changed

**When user approves:**

- User explicitly says "commit", "yes", "go ahead", etc.
- User provides commit message
- User reviews diffs and approves

**NEVER commit when:**

- âŒ User hasn't explicitly approved
- âŒ User hasn't reviewed changes
- âŒ User said "don't commit" or "wait"
- âŒ Changes are incomplete or untested

**Example workflow:**

```text

AI: I've fixed the issue. Here are the changes:

    - Modified: config.py (removed duplicate validator)
    - Modified: Makefile (removed || true from security-audit)

    [Shows git diff]

    Should I commit these changes?

User: Yes, commit with message "fix: remove duplicate validator and fix security audit"

AI: [Commits with user's message]

```text

1. âœ… **Run appropriate tests first** (see [Testing After Changes](#-critical-running-tests-after-making-changes) section):
   - Start with `make test-ci-fast` (fast tests, ~6-10 min)
   - If changes touch slow test areas, also run slow tests (`make test-integration-slow` or `make test-e2e-slow`)
2. âœ… Run `make ci` locally to verify all checks pass (includes fast tests with coverage)
3. âœ… **Conditionally run `make docker-test`** if Docker-related changes exist (see below)
4. âœ… Fix any failures before pushing
5. âœ… Only push after all tests and `make ci` (and `make docker-test` if applicable) pass completely

**What `make ci` checks:**

- Formatting (black, isort)
- Linting (flake8, markdownlint)
- Type checking (mypy)
- Security (bandit, pip-audit)
- Tests (unit + fast integration + fast e2e, with coverage) - **Note: Excludes slow/ml_models tests**
- Documentation build (mkdocs)
- Package build (source + wheel)

**Testing Strategy:**
- **During development:** Run `make test-ci-fast` after each change (fast feedback)
- **Before push:** Run `make ci` (full validation with fast tests)
- **If changes touch slow test areas:** Also run slow tests before push (see testing section)

**When to run `make docker-test` (CONDITIONAL):**

**Run `make docker-test` BEFORE pushing to PR ONLY if you made significant changes to:**

- âœ… **Dockerfile** (`docker/Dockerfile`) - Any changes to build process, dependencies, or structure
- âœ… **Project structure** - Changes to package layout, subpackages, or file organization that could affect Docker build
- âœ… **Dependencies** - Changes to `pyproject.toml` that affect Docker installation (core dependencies, package metadata, subpackages)
- âœ… **Package configuration** - Changes to `[tool.setuptools]` in `pyproject.toml` (packages list, package-dir, etc.)

**When NOT to run `make docker-test`:**

- âŒ Only Python code changes (no Dockerfile or structure changes)
- âŒ Only documentation changes
- âŒ Only test file changes
- âŒ Only configuration file changes (that don't affect Docker)

**Why this matters:**

- Prevents CI failures that waste time
- Catches issues locally before they reach GitHub
- Ensures PR is ready for review
- Maintains code quality standards
- Docker builds are slow - only run when necessary

**Workflow:**

```bash

# After making changes and committing:

# Step 1: Show user what will be pushed

git status
git diff --stat  # or git log --oneline origin/branch-name..HEAD

# Step 2: Run appropriate tests (see Testing After Changes section)

# Start with fast tests (if not already run during development)

make test-ci-fast

# Step 3: Run slow tests if changes touch slow test areas

# (Only if you changed ML model code, slow integration/E2E tests, etc.)

# make test-integration-slow  # If changed integration code with ML

# make test-e2e-slow          # If changed E2E code with ML

# Step 4: Always run full CI validation

make ci

# Step 5: Conditionally run Docker tests (if Docker-related changes)

# Check if you modified Dockerfile, pyproject.toml structure, or package layout

if [ -n "$(git diff --name-only HEAD | grep -E '(Dockerfile|pyproject\.toml|package structure)')" ]; then
    make docker-test
fi

# Step 6: ASK USER FOR APPROVAL

# "I've made the following changes: [summary]

#  Tests passed (fast tests + slow tests if applicable).

#  CI checks passed. Should I push these changes to the PR?"

# Step 7: WAIT for user to explicitly approve (user says "yes", "push", "go ahead", etc.)

# Step 8: ONLY THEN push (after user approval)

git push origin feature/branch-name

# If tests or CI fails â†’ Fix issues â†’ Run tests and make ci again â†’ Ask for approval again

```text

- âŒ **User hasn't explicitly approved the push** (MOST IMPORTANT - CHECK THIS FIRST)
- âŒ **You haven't shown `git status` first**
- âŒ **You haven't shown `git diff` or change summary first**
- âŒ **User said "don't push" or "wait"**
- âŒ `make ci` hasn't been run
- âŒ `make ci` has failures
- âŒ `make docker-test` hasn't been run (when Docker-related changes exist)
- âŒ `make docker-test` has failures (when Docker-related changes exist)
- âŒ Tests are failing
- âŒ Linting errors exist
- âŒ Documentation build fails

**CORRECT PUSH WORKFLOW:**

```bash

# Step 1: Show what will be pushed

git status
git diff origin/feature/branch-name..HEAD  # or git log --oneline

# Step 2: Run appropriate tests (if not already run)

make test-ci-fast

# (and slow tests if changes touch slow test areas)

# Step 3: Run CI checks

make ci

# (and make docker-test if applicable)

# Step 4: ASK USER FOR APPROVAL

# "I've resolved the conflicts and fixed linting errors.

#  Changes include: [summary]

#  Tests passed. CI checks passed. Should I push these changes to the PR?"

# Step 5: WAIT for user to say "yes", "push", "go ahead", etc.

# Step 6: ONLY THEN push

git push origin feature/branch-name

```yaml

- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation
- `test`: Tests
- `refactor`: Code refactoring
- `ci`: CI/CD changes
- `chore`: Maintenance
- `perf`: Performance

**Examples:**

```text

feat: add PostgreSQL export adapter

Implement export functionality to generate SQL dumps from
episode metadata. Includes schema templates and CLI flags.

Fixes #40

```text

# Docs

docs/update-api-reference
docs/contributing-guide

# Refactoring

refactor/simplify-config-loading

```text

              â”œâ”€ Yes â†’ Create RFC
              â””â”€ No â†’ Skip, just implement

```text
```text
```text

- Multiple valid approaches exist
- User preference matters (performance vs readability)
- Breaking changes are needed
- Trade-offs aren't obvious

**External dependencies:**

- Need to add new dependencies
- Need to change dependency versions
- Security implications

**Design decisions:**

- Architectural changes
- API design choices
- Performance vs correctness trade-offs

**Examples:**

- "Should I use async/await or keep synchronous?"
- "This requires adding a new dependency (X). Is that okay?"
- "This is a breaking change to the API. Should I proceed?"

## Don't Ask When

**Patterns are clear:**

- Following established patterns in codebase
- Standard bug fix approach
- Documentation-only changes
- Obvious code improvements (typos, formatting)

**Best practices:**

- Adding type hints
- Adding tests for new code
- Improving error messages
- Adding docstrings

**Examples:**

- "Should I add a docstring?" â†’ Yes, always (don't ask)
- "Should I add tests?" â†’ Yes, always (don't ask)
- "Should I format with black?" â†’ Yes, always (don't ask)

---

## Quick Reference

### Most Common Commands

```bash

make install-hooks        # Install pre-commit hook (one-time setup)
make format               # Format code
make test-ci-fast         # Fast tests (unit + fast integration + fast e2e, ~6-10 min)
make test-integration-slow # Slow integration tests (if needed, ~5-10 min)
make test-e2e-slow        # Slow E2E tests (if needed, ~15-20 min)
make ci                   # Full CI suite (formatting, linting, tests, docs, build)
make docs                 # Build docs
make lint-markdown        # Check markdown files
make clean                # Clean build artifacts

```python

# Service API

from podcast_scraper import service
result = service.run(cfg)

# Progress

from podcast_scraper import progress
with progress.make_progress(...) as pbar:
    pbar.update(1)

# Logging

import logging
logger = logging.getLogger(__name__)
logger.info("message")

# Prompts (when implemented)

from podcast_scraper.prompt_store import render_prompt
prompt = render_prompt("summarization/long_v1", **params)

```python

import os
from pathlib import Path
from typing import Optional, List, Dict

# Third-party (group 2)

import requests
from pydantic import BaseModel

# Local (group 3)

from podcast_scraper import config
from podcast_scraper.models import Episode

```text

- **[CONTRIBUTING.md](CONTRIBUTING.md)** - Human contributor guide (quick start, setup, workflow, PR process)
- **[docs/DEVELOPMENT_GUIDE.md](docs/DEVELOPMENT_GUIDE.md)** - **ðŸ“š Detailed technical information** (code style, testing, CI/CD, architecture, logging, documentation standards, markdown linting)
- **[docs/CI_CD.md](docs/CI_CD.md)** - CI/CD pipeline documentation with visualizations
- **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)** - Architecture design and module responsibilities
- **[docs/TESTING_STRATEGY.md](docs/TESTING_STRATEGY.md)** - Comprehensive testing approach
- **[docs/api/](docs/api/)** - Auto-generated API reference
- **[README.md](README.md)** - User-facing documentation
- **[docs/rfc/RFC-015-ai-experiment-pipeline.md](docs/rfc/RFC-015-ai-experiment-pipeline.md)** - AI experiment pipeline design
- **[docs/rfc/RFC-016-modularization-for-ai-experiments.md](docs/rfc/RFC-016-modularization-for-ai-experiments.md)** - Provider system architecture
- **[docs/rfc/RFC-017-prompt-management.md](docs/rfc/RFC-017-prompt-management.md)** - Prompt management system
- **[docs/rfc/RFC-013-openai-provider-implementation.md](docs/rfc/RFC-013-openai-provider-implementation.md)** - OpenAI provider design

**When you need detailed technical information:**

- Code style details â†’ See `docs/DEVELOPMENT_GUIDE.md` (Code Style Guidelines section)
- Testing details â†’ See `docs/DEVELOPMENT_GUIDE.md` (Testing Requirements section)
- CI/CD details â†’ See `docs/DEVELOPMENT_GUIDE.md` (CI/CD Integration section)
- Architecture patterns â†’ See `docs/DEVELOPMENT_GUIDE.md` (Architecture Principles section)
- Logging patterns â†’ See `docs/DEVELOPMENT_GUIDE.md` (Logging Guidelines section)
- Documentation standards â†’ See `docs/DEVELOPMENT_GUIDE.md` (Documentation Standards section)

---

## Summary for AI Assistants

**Remember:**

**ðŸš¨ TOP 2 CRITICAL RULES (MUST FOLLOW - NO EXCEPTIONS):**

1. âœ… **ALWAYS show changes and get approval before committing** (CRITICAL)
   - **MANDATORY CHECKLIST:** `git status` â†’ `git diff` â†’ Wait for approval â†’ Get message â†’ THEN commit
   - **NEVER skip any step. NEVER assume approval.**

2. âœ… **ALWAYS show `git status` and `git diff` before pushing to PR** (CRITICAL)
   - **MANDATORY:** Show user what will be pushed â†’ Get approval â†’ THEN push
   - **NEVER push without showing changes first.**
3. âœ… **ALWAYS get explicit user approval before pushing to PR** (CRITICAL)
   - **MANDATORY:** Ask user â†’ Wait for "yes"/"push"/"go ahead" â†’ THEN push
   - **NEVER push without explicit user approval.**
4. âœ… **ALWAYS run appropriate tests after making changes** (CRITICAL)
   - **MANDATORY:** Start with `make test-ci-fast` (fast tests, ~6-10 min)
   - **MANDATORY:** If changes touch slow test areas (ML models, slow integration/E2E), also run slow tests
   - **MANDATORY:** Run `make ci` before pushing (includes fast tests with coverage)
   - **NEVER skip tests. ALWAYS run fast tests first, then slow tests if needed.**
5. âœ… **ALWAYS run `make ci` before pushing to PR** (new or updated PR) (CRITICAL)
   - **MANDATORY:** Run `make ci` â†’ Verify passes â†’ Fix failures â†’ Ask for approval â†’ THEN push
   - **NEVER push without running `make ci` first.**
6. âœ… **CONDITIONALLY run `make docker-test` before pushing to PR** (when Docker-related changes exist) (CRITICAL)
   - **MANDATORY:** If you changed Dockerfile, pyproject.toml structure, or package layout â†’ Run `make docker-test` â†’ Verify passes â†’ Ask for approval â†’ THEN push
   - **NEVER push Docker-related changes without running `make docker-test` first.**
7. âœ… Install pre-commit hook with `make install-hooks` (prevents CI failures)
8. âœ… Run `make fix-md` before committing markdown files (fixes common linting issues)
9. âœ… **Self-check markdown files before finishing:** Scan for one H1 only, blank lines after headings, no trailing spaces, consistent list indentation, code fences have language tags
9. âœ… Run `make format` and `make test-ci-fast` before committing (if no hook)
5. âœ… Respect module boundaries (no business logic in CLI, no HTTP in config, etc.)
6. âœ… Mock external dependencies in tests
7. âœ… Add docstrings to all public functions (Google-style)
8. âœ… Use Config for all runtime options
9. âœ… Never commit secrets or personal data
10. âœ… Create PRD for user-facing features, RFC for architecture changes
11. âœ… Update README when CLI changes
12. âœ… Follow conventional commit format
13. âœ… Ask when uncertain, don't ask for obvious best practices
14. âœ… Use lazy loading pattern for `cli` and `service` imports
15. âœ… Update index files (`docs/index.md`, `docs/rfc/index.md`, `docs/prd/index.md`) when adding RFCs/PRDs
16. âœ… Use `python-dotenv` for environment variable management (`.env` files)
17. âœ… Treat prompts as provider-specific concerns (not part of core protocol)

**When in doubt:**

- Check existing code for patterns
- Look at similar functions for examples
- Read ARCHITECTURE.md for design principles
- Read docs/CI_CD.md for CI/CD pipeline details
- Read relevant RFCs/PRDs for feature context
- Run `make ci` to validate changes

---

---

## ðŸ”’ How to Ensure AI Follows These Rules

**As a user, you can enforce these rules by:**

### 1. **Start-of-Session Reminder**

At the beginning of a session, ask:

- "Did you read the AI guidelines?"
- "Check the guidelines before we start"
- "Follow the guidelines in `.ai-coding-guidelines.md`"

### 2. **Before Critical Actions**

Before commits or pushes, ask:

- "Show me what you're about to commit/push"
- "Did you check the guidelines for commits/pushes?"
- "Wait, let me review first" (this should STOP the AI)

### 3. **Verification Questions**

Ask the AI to confirm:

- "What are the rules for pushing to PR?"
- "What's the commit workflow?"
- "Show me the checklist before you push"

### 4. **Explicit Stop Commands**

If AI tries to push/commit without approval:

- Say "STOP" or "Don't push yet"
- The AI MUST stop and wait for approval

### 5. **Regular Reminders**

Periodically remind:

- "Remember: always ask before pushing"
- "Check the guidelines again"
- "What does the guideline say about [action]?"

**The AI should acknowledge these reminders and follow them.**

---

**Version:** 2.1 (added explicit user approval requirements and enforcement guide)
**Last Updated:** 2025-12-26

````
